# 情境學習 (In-Context Learning, ICL)
**情境學習 (In-Context Learning, ICL)** 是一種語言模型現象，模型可以根據提供的範例來產生預測的標記，而不需要任何額外的微調。

---

## 起源
* 情境學習一詞源自 [**GPT-3** 的論文](https://arxiv.org/pdf/2005.14165.pdf)，當時研究人員發現語言模型訓練到後面，突然開始浮現一種能力：
    * 如果將有標記的範例按照一個**固定的格式**排好，並且把沒有標記的輸入放在提示的最後面，模型就會自己生成正確答案出來。這個格式甚至可以非常隨意，只需要前後一致即可。
* 雖然名稱帶有**學習**一詞，但他其實並不是一種訓練手法，本質上是一種被觀察到的**現象**。
* 為何語言模型會產生情境學習能力呢？
    * 至今也沒有一個非常好的解釋，但因為情境學習的方便性與擴展性，現在已經被當成一種提示的技巧，廣泛應用於各個領域。
* 情境學習的用法聽起來似乎與少量樣本提示 (Few-Shot Prompting) 很像！
    * 沒有錯，兩者的核心概念都是**提供範例**給語言模型。
    * 但情境學習通常更著重在**範例格式**上，而且也不會預設範例一定很少量。
    * 少量樣本提示通常只要有給範例就好，格式並不是主要關注的重點，有時範例裡面可能還會包含詳細的解釋，因此也能說少量樣本提示是較為廣義的情境學習。

---

## 基本
* 情境學習的初始概念相當簡單，只需要給模型一組固定格式的資料即可：
    ```
    今天天氣真好 => Positive
    今天天氣真差 => Negative

    好煩喔又下雨 =>
    ```
    * 將以上這段提示丟進 ChatGPT 做測試，無論是 GPT-3.5或 GPT-4 都會回覆 Negative。
    * 甚至不需要告訴模型實際的任務與標籤的定義是什麼，模型就能很自然的推理出正確答案。
* 在情境學習裡面，可以使用任意格式，只需要前後一致即可，例如：
    ```
    Input: 這部電影真好看
    Label: Positive

    Input: 這個編劇也太瞎
    Label: Negative

    Input: 運鏡流暢氣氛佳
    Label:
    ```
* 情境學習與少量樣本提示非常相似，但少量樣本提示更傾向於借助模型**遵循指令**的能力來解決問題，而情境學習通常只需要模型有**文字接龍**的能力就能發揮，也就是說即便模型沒有做過指令微調，也具有情境學習的能力！
    * 這個能力使研究人員十分驚訝，彈性的格式與相當泛化的準確率，這不就代表語言模型不再需要任何額外的微調，就能夠快速適應到任何領域的任務上嗎！！
    * 於是大家開始好奇，語言模型的情境學習能力究竟是從何而來？
* 事實上目前還沒有一個很共識的定論，有人認為語言模型並不是真的從範例去學習如何預測，而是模型本來就有分類能力。也有人認為情境學習的提示本身就是一種相當小型的微調，是一種廣義的元學習 (Meta Learning)。
    * 這部份的研究屬於**黑盒解釋 (Blackbox Interpret)** 的領域， 有興趣的話可以找些相關的介紹來看看。
* 這些具有情境學習能力的模型，通常訓練資料都相當豐富，模型本身在其他任務上也具有相當泛化的能力。
    * 因此不是只有 GPT-3 這種等級的語言模型才具備情境學習的能力，其實像是 Llama 7B 乃至於 GPT-2 這些小模型也都存在情境學習的能力，差別只在於這個模型的能力是否顯著、泛化與足夠準確等等。

---

## 翻譯應用
* 除了簡單的情感分類以外，情境學習也能應用在翻譯任務上，雖然語言模型本身已經具備相當不錯的翻譯能力，但某些用詞可能不盡人意：
    ```
    "I need a printer to print my code" 翻譯成中文
    ```
    翻譯使用大陸常用語：
    ```
    I need a printer to print my code => 我需要一臺打印機來打印我的代碼
    ```
* 我們能透過情境學習讓翻譯的用詞更為精緻，例如：
    ```
    printer => 印表機
    print => 列印
    code => 程式碼
    I need a printer to print my code =>
    ```
    ```
    I need a printer to print my code => 我需要一台印表機來列印我的程式碼
    ```
* 除了這種文化用語以外，翻譯罕見詞或新詞時也特別好用，例如遊戲技能的翻譯，就經常有遊戲自己獨樹一格的翻譯方式，這時就很適合借助情境學習的能力來協助翻譯。

---

## 文字正規化應用
* **文字正規化 (Text Normalization, TN)** 也是個相當適合套用情境學習的領域，例如一個阿拉伯數字經常有多種中文數字的念法：
    ```
    1 => ㄧ
    2 => 二、兩
    3 => 三
    11 => 十一
    20 => 二十
    22 => 二十二、二二
    200 => 兩百
    201 => 兩百零一、二百零一、二零一
    257 =>
    ```
    ```
    257 => 二百五十七、兩百五十七、二五七
    ```
* 再也不用寫那些充滿複雜規則的程式來產生中文數字念法了！只需要列舉一些念法的例子，模型就能舉一反三。
* 若是遇到客製化的需求，例如軍隊的數字念法或銀行轉帳用的大寫中文數字等，也只需要稍微修改例子即可。

---

## 連結
* [arXiv Paper: Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)
* [arXiv Paper: An Explanation of In-context Learning as Implicit Bayesian Inference](https://arxiv.org/abs/2111.02080)
* [arXiv Paper: Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?](https://arxiv.org/abs/2202.12837)
* [arXiv Paper: Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers](https://arxiv.org/abs/2212.10559)
* [arXiv Paper: In-Context Learning in Large Language Models Learns Label Relationships but Is Not Conventional Learning](https://arxiv.org/abs/2307.12375)

---

## 結論
* 本章節介紹了情境學習的提示技巧，透過這個技巧就能輕鬆的將語言模型導入目標任務上。
* 除了翻譯與文字正規化以外，還有相當多可以應用情境學習的場景。
* 使用情境學習最大的優點在於不需要對模型進行額外的微調，而且就算是小參數量的模型也具有情境學習的能力。相對於其他機器學習方法而言，**可解釋性**也相當高，通常只要觀察給定範例是否有錯，就可以知道為何模型會答錯。
    * 然而事實上語言模型本身依然是高度不可解釋性的黑盒子，但基於語言模型的情境學習卻是具有可解釋性的？
    * 其實就連語言模型為何會產生情境學習的能力都沒有很好的解釋，而情境學習所謂的解釋性高其實也只是指「容易偵錯」的部份而已。
    * 即便情境學習的能力很強大，但有時還是會遇到一些莫名錯掉的例子，唯一的解釋就是他沒有在範例裡面或範例不夠多。
    * 這到底算不算是一種可解釋性高呢？也許是這個領域還需要多加探索的部份。

---