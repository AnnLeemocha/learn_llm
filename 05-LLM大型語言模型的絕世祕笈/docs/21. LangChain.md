# LangChain
å‰é¢å¹¾å€‹ç« ç¯€æåˆ°çš„æ¡†æ¶ï¼Œå¤§å¤šå±¬æ–¼åº•å±¤æ¨è«–é¡ï¼Œä½†ä¸Šå±¤çš„æ‡‰ç”¨é–‹ç™¼é¡ä¹Ÿæ˜¯è¨±å¤šäººé—œæ³¨çš„ç„¦é»ï¼Œå…¶ä¸­æœ€ç‚™æ‰‹å¯ç†±çš„é [LangChain](https://www.langchain.com/) è«å±¬ã€‚
* é–‹å§‹å¯¦éš›ä½¿ç”¨èªè¨€æ¨¡å‹é€²è¡Œæ‡‰ç”¨é–‹ç™¼æ™‚ï¼Œæœƒé¢è‡¨åˆ°è¨±å¤šé›œä¸ƒé›œå…«çš„æç¤ºæ¨£æ¿ã€é‡è¤‡çš„ç”Ÿæˆç¨‹åºä»¥åŠå›ºå®šç‘£ç¢çš„ä¸²æ¥æµç¨‹ç­‰ç­‰ã€‚
* å¤šæ•¸æƒ…æ³ä¸‹ï¼Œé€™äº›æ¨£æ¿ã€æµç¨‹åˆ‡é–‹ä¾†çœ‹ï¼Œéƒ½ä¸æ˜¯å¾ˆè¤‡é›œçš„ç¨‹å¼ï¼Œè‡ªå·±å‹•æ‰‹å¯«ä¹Ÿéƒ½ä¸é›£å¯«ã€‚
* ä½†æ˜¯ç•¶ä¸åŒçš„æµç¨‹é–‹å§‹å †ç–Šå‡ºæ›´é¾å¤§ã€æ›´è¤‡é›œçš„æ‡‰ç”¨æ™‚ï¼Œé€™ä¸€åˆ‡å°±æœƒé¡¯å¾—ååˆ†æ··äº‚ã€‚
* é€™æ™‚å°±èƒ½å€ŸåŠ© LangChain ä¾†å¹«æˆ‘å€‘é€²è¡Œæ›´å¥½çš„ç¨‹å¼ç¢¼ç®¡ç†ã€‚
* å¦‚æœæƒ³çœ‹ LangChain Pro çš„å¯ä»¥åƒè€ƒ Ted Chen å¤§å“¥çš„[ç³»åˆ—æ–‡](https://ithelp.ithome.com.tw/users/20154415/ironman/6008)ã€‚

---

## é¡Œç›®
ä¸­äºŒæŠ€èƒ½ç¿»è­¯ç³»çµ±ã€‚

---

## è³‡æ–™ä¾†æº
æƒ³è¦è£½ä½œä¸€å€‹ä¸­äºŒæŠ€èƒ½ç¿»è­¯ç³»çµ±ï¼Œå‹¢å¿…éœ€è¦ä¸€äº›ä¸­äºŒçš„ç¿»è­¯è³‡æ–™ï¼Œä½†æ˜¯å“ªè£¡å¯ä»¥ç²å¾—é€™ç¨®ä¸­äºŒçš„è³‡æ–™å‘¢ï¼Ÿ
* é€™æ™‚ç­†è€…å°±æŠŠæ­ªè…¦ç­‹å‹•åˆ°è‹±é›„è¯ç›Ÿçš„ [Riot API](https://tinyurl.com/llm-riot-api) ä¸Šäº†ï¼è‹±é›„è¯ç›Ÿæœ‰ä¸Šç™¾ä½è‹±é›„ï¼Œæ¯å€‹è‹±é›„çš„æŠ€èƒ½éƒ½æ˜¯ç”±çœŸäººç²¾å¿ƒç¿»è­¯çš„ï¼Œå› æ­¤æ˜¯å€‹ç¿»è­¯å“è³ªç›¸ç•¶ä¸éŒ¯çš„é¸æ“‡ï¼
* ç­†è€…å…ˆæ‰‹å‹•å–ä¸€äº›æ¨£æœ¬ï¼Œä¾†å±•ç¤ºé€™å€‹ä¸­äºŒç³»çµ±çš„æ ¸å¿ƒæ¦‚å¿µï¼š
    ```!
    è«‹æ ¹æ“šä»¥ä¸‹ç¯„ä¾‹ï¼Œç”¢ç”Ÿä¸€å€‹ä¸­äºŒçš„æŠ€èƒ½ç¿»è­¯ï¼Œåªéœ€è¦å›ç­”ç¿»è­¯å°±å¥½ã€‚

    Source: The Darkin Blade
    Target: å†¥è¡€é‚ªåŠ

    Source: Infernal Chains
    Target: å†¥åºœè¡€éˆ

    Source: Umbral Dash
    Target: å†¥å½±è¡é‹’

    Source: World Ender
    Target: åŠé­”æ»…ä¸–

    Source: Lightning Slash In The Dark
    Target:
    ```
    * å°‡é€™ä»½æç¤ºä¸Ÿé€² ChatGPT æ¸¬è©¦ï¼Œå¾—åˆ°ä¸€å€‹ã€Œ**å†¥é›·æš—ç ´**ã€çš„ç¿»è­¯ï¼Œæœ‰é‚£éº¼ä¸€ä¸Ÿä¸Ÿè¦æˆç‚ºå½±ä¹‹å¼·è€…çš„æ„Ÿè¦ºäº†ï¼
    * ç­†è€…ä¹Ÿå¦å¤–å¯¦æ¸¬äº†ä¸€ä¸‹Llama 38B çš„çµæœï¼Œå¾—åˆ°ã€Œ**æš—é›»åŠˆå†¥**ã€çš„ç¿»è­¯ï¼Œå“‡ï¼æ„Ÿè¦ºå¿ƒä¸­æœ‰æŸç¨®ç¥å¥‡çš„æ±è¥¿åœ¨ç‡ƒç‡’äº†ï¼

---

## è³‡æ–™çˆ¬å–
å®˜æ–¹æ–‡ä»¶å…¶å¯¦æè¿°çš„æ»¿è©³ç´°ï¼Œæˆ‘å€‘éœ€è¦å…ˆç²å–å…¨éƒ¨çš„è‹±é›„åˆ—è¡¨ï¼Œç„¶å¾Œæ ¹æ“šè‹±é›„åç¨±ä¸€ä¸€æŠ“å–å„è‡ªçš„è³‡æ–™ã€‚
* æˆ‘å€‘å…ˆæ‰‹å‹•æŠ“å–å…¨éƒ¨çš„è‹±é›„åˆ—è¡¨ï¼Œå¯ä»¥å¾ä»¥ä¸‹é€£çµç²å¾—ï¼š
    ```!
    https://ddragon.leagueoflegends.com/cdn/14.10.1/data/en_US/champion.json
    ```
    * ç¶²å€è£¡é¢çš„ `14.10.1` æ˜¯éŠæˆ²ç‰ˆæœ¬ï¼Œå¦‚æœæ‡·å¿µè²æ­æ‹‰çš„èˆŠç‰ˆå¤§çµ•åç¨±ï¼Œå¯ä»¥è€ƒæ…®å›æº¯åˆ° `5.14.1` ä¹‹å‰çš„ç‰ˆæœ¬å»æŠ“å–ã€‚
    * è€Œ `en_US` ä»£è¡¨èªè¨€æ˜¯è‹±æ–‡çš„æ„æ€ï¼Œå› ç‚ºæ‰€æœ‰è‹±é›„çš„ç´¢å¼•éƒ½æ˜¯ä½¿ç”¨è‹±æ–‡ï¼Œæ‰€ä»¥é€™å€‹æ­¥é©Ÿåªéœ€è¦è‹±æ–‡è³‡æ–™ã€‚
* æ¥ä¸‹ä¾†é–‹å§‹çˆ¬å–è‹±é›„çš„æŠ€èƒ½è³‡æ–™ï¼Œæ¯å€‹è‹±é›„è³‡æ–™çš„ API æ ¼å¼å¦‚ä¸‹ï¼š
    ```!
    http://ddragon.leagueoflegends.com/cdn/13.19.1/data/<lang>/champion/<champ>.json
    ```
    * `<lang>` ç‚ºèªè¨€ä»£è™Ÿï¼Œè€Œ `<champ>` ç‚ºè‹±é›„çš„è‹±æ–‡åå­—ã€‚
    * æˆ‘å€‘æœƒåˆ†åˆ¥çˆ¬å–è‹±æ–‡ `en_US` èˆ‡ç¹é«”ä¸­æ–‡ `zh_TW` å…©ç¨®èªè¨€çš„è³‡æ–™ã€‚
* é¦–å…ˆå®šç¾©çˆ¬å–çš„å‡½å¼ï¼š
    ```python
    import json
    import os
    import requests

    def get_data(champ, lang, ver="14.10.1"):
        # å–å¾—è³‡æ–™
        cdn_url = f"http://ddragon.leagueoflegends.com/cdn/{ver}/data"
        url = f"{cdn_url}/{lang}/champion/{champ}.json"
        resp = requests.get(url)

        # å¯«å…¥æª”æ¡ˆ
        fn = f"data/{lang}/{champ}.json"
        os.makedirs(f"data/{lang}", exist_ok=True) 
        with open(fn, "wt", encoding="UTF-8") as fp:
            fp.write(resp.text)
    ```
* çˆ¬èŸ²çš„éç¨‹ï¼Œå¯ä»¥å–„ç”¨ Python å…§å»ºçš„ `concurrent` å¥—ä»¶ä¾†æ¸›å°‘ç­‰å¾…æ™‚é–“ï¼š
    ```python
    from tqdm import trange
    from concurrent, futures import ThreadPoolExecutor, as_completed

    with open("champion.json", "rt", encoding="UTF-8") as fp:
        data: dict = json.load(fp)["data"]

    with ThreadPoolExecutor(max_workers=16) as tpe:
        futures = [
            tpe.submit(get_data, champ, lang)
            for champ in data.keys()
            for lang in ("en_US", "zh_TW")        
        ]

        with trange(len(futures), ncols=100) as prog:
            [prog.update() for _ in as_completed(futures)]
    ```
    * é€™æ¨£ä¸‰ç™¾å¤šç­†è³‡æ–™ä¸ç”¨ 10 ç§’é˜å°±å¯ä»¥å…¨éƒ¨ä¸‹è¼‰å®Œå›‰ï¼
* è‹¥æƒ³è¦å…¶ä»–èªè¨€å¯åƒè€ƒ[é€™ç¯‡è³‡è¨Š](https://developer.riotgames.com/docs/lol#data-dragon_data-assets)åšèª¿æ•´ã€‚ 
* è£œå……ï¼š
    * å¦‚æœä½ ç¶“å¸¸è¦ºå¾— `tqdm` å¥—ä»¶çš„é€²åº¦æ¢å¤ªå¯¬å¤ªä½”ç‰ˆé¢ï¼Œé™¤äº†é€é `ncols` åƒæ•¸è¨­å®šä»¥å¤–ï¼Œä¹Ÿå¯ä»¥é€éç’°å¢ƒè®Šæ•¸ `TQDM_NCOLS` ä¾†è¨­å®šæ‰€æœ‰ `tqdm` é€²åº¦æ¢çš„å¯¬åº¦ï¼Œä½†æ˜¯å¦‚æœè©²é€²åº¦æ¢æœ‰è¨­å®š `dynamic_ncols` çš„è©±å°±æœƒå¤±æ•ˆã€‚
* æ¥è‘—ä¾åºæ‹œè¨ªé€ å‹å¤–è§€åç¨±ã€ä¸»å‹•æŠ€èƒ½åç¨±ã€è¢«å‹•æŠ€èƒ½åç¨±ï¼Œé€™äº›éƒ½æ˜¯é‡è¦çš„ä¸­äºŒè¦ç´ ä¾†æºï¼Œå»ºç«‹ä¸­è‹±æŠ€èƒ½è³‡æ–™é›†çš„ç¨‹å¼ç¢¼å¦‚ä¸‹ï¼š
    ```python
    import json

    def load_json(file_path):
        with open(file_path, "rt", encoding="UTF-8") as fp:
            return json.load(fp)

    def create_item(source, target):
        return {"source": source, "target": target}

    datasets = list()
    data: dict[str, dict] = load_json("champion.json")

    for champ in data["data"].keys():
        # è®€å–è‹±é›„è³‡æ–™
        en_data = load_json(f"data/en_US/{champ}.json")
        zh_data = load_json(f"data/zh_TW/{champ}.json")

        # å¤–è§€é€ å‹åç¨±
        en_skins = en_data["data"][champ]["skins"]
        zh_skins = zh_data["data"][champ]["skins"]

        # è·³éç¶“å…¸é€ å‹
        for en_sk, zh_sk in zip(en_skins[1:], zh_skins[1:]):
            en_sk_name = en_sk["name"]
            zh_sk_name = zh_sk["name"]
            datasets.append(create_item(en_sk_name, zh_sk_name))

        # ä¸»å‹•æŠ€èƒ½åç¨±
        en_spells = en_data["data"][champ]["spells"]
        zh_spells = zh_data["data"][champ]["spells"]
        for en_sp, zh_sp in zip(en_spells, zh_spells):
            en_name, zh_name = en_sp["name"], zh_sp["name"]
            datasets.append(create_item(en_name, zh_name))

        # è¢«å‹•æŠ€èƒ½åç¨±
        en_pass = en_data["data"][champ]["passive"]["name"]
        zh_pass = zh_data["data"][champ]["passive"]["name"]
        datasets.append(create_item(en_pass, zh_pass))

    with open("datasets.json", "wt", encoding="UTF-8") as fp:
        json.dump(datasets, fp, ensure_ascii=False, indent=4)
    ```
    * åˆ°é€™è£¡å®Œæˆè³‡æ–™é›†çš„å»ºç«‹ï¼Œæ¥ä¸‹ä¾†æ­£å¼é€²å…¥ LangChain çš„éƒ¨åˆ†ï¼

---

## LLM
LangChain å…¶å¯¦å¾ˆè¬›ç©¶**å…ƒä»¶é–“çš„äº’å‹•**ï¼Œåœ¨ææ‡‚äº’å‹•ä¹‹å‰ï¼Œéµå®šè¦å…ˆææ‡‚å…ƒä»¶ï¼
* åœ¨ LangChain è£¡é¢çš„å…ƒä»¶å¤šæ•¸å¯ä»¥ç¨ç«‹é‹ä½œï¼Œå…ˆä¾†å®‰è£ç›¸é—œå¥—ä»¶ï¼š
    ```bash
    pip install langchain langchain-community langchain-openai
    ```
* LangChain çš„ç‰¹è‰²ä¹‹ä¸€åœ¨æ–¼æ•´åˆäº†ç›¸ç•¶å¤šç›¸é—œçš„å¥—ä»¶æ¡†æ¶ï¼Œè®“æˆ‘å€‘å¯ä»¥ç”¨çµ±ä¸€çš„ä»‹é¢å»æ“ä½œï¼Œä¾‹å¦‚LLMé¡åˆ¥å°±æœ‰æ•´åˆ OpenAlã€ggmlã€vLLM æˆ– TGI ç­‰èªè¨€æ¨¡å‹å¾Œç«¯æ¡†æ¶ã€‚
* ä½†æ˜¯æ¡†æ¶é€™éº¼å¤šï¼Œæœ‰é¸æ“‡éšœç¤™æ€éº¼è¾¦ï¼Ÿ
    * é‚„è¨˜å¾—å‰é¢çš„ç« ç¯€æœ‰æåˆ°ï¼Œé€™äº›æ¡†æ¶å…¶å¯¦éƒ½æœ‰æä¾›ç›¸å®¹ OpenAI API çš„ç”¨æ³•å—ï¼Ÿ

### é¸æ“‡ vLLM ç•¶ä½œä¸»è¦çš„å¾Œç«¯æ¡†æ¶ä¾†é€²è¡Œæ¨è«–ï¼š
åœ¨ LangChain è£¡é¢ï¼Œä¸€æ¨£å¯ä»¥æŠŠå®ƒç•¶æˆ OpenAI API ä¾†ç”¨ã€‚
* é¦–å…ˆå•Ÿå‹•ä¸€å€‹ vLLM æœå‹™ï¼š
    ```bash
    python -m vllm.entrypoints.openai.api_server \
        --model meta-llama/Meta-Llama-3-8B-Instruct \
        --api-key auth-token-ouo123
    ```
* åœ¨ LangChain è£¡é¢ LLM çš„åŸºæœ¬ç”¨æ³•å¦‚ä¸‹ï¼š
    ```python
    from langchain.callbacks import StreamingStdOutCallbackHandler
    from langchain_openai import OpenAI

    llm  = OpenAI(
        api_key="auth-token-ouo123", 
        model="meta-llama/Meta-Llama-3-8B-Instruct", 
        base_url="http://localhost:8000/v1", 
        callbacks=[StreamingStdOutCallbackHandler()], 
        streaming=True,
    )

    llm.invoke("hello, i am", stop=("\n"))
    ```
    * å°‡ `base_url` åƒæ•¸æ›æˆ vLLM Server çš„è·¯å¾‘ï¼Œç„¶å¾Œå¡«å…¥å•Ÿç”¨ vLLM æ™‚è¨­å®šçš„ API Keyï¼Œä¸¦æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹åç¨±å°±å¯ä»¥å›‰ï¼
    * å¦å¤–è¨­å®š `streaming=True` çš„åƒæ•¸ä¹‹å¾Œï¼Œå°±å¯ä»¥æ­é…ä¸Šé¢çš„ Callback é€²è¡Œä¸²æµè¼¸å‡ºã€‚

### é¸æ“‡ Hugging Face Text Generation Inference ç•¶ä½œä¸»è¦çš„å¾Œç«¯æ¡†æ¶ä¾†é€²è¡Œæ¨è«–ï¼š
* åœ¨æ­¤ä¹‹å‰ï¼Œéœ€è¦å…ˆå°‡ TGI Service è·‘èµ·ä¾†ï¼Œå¯ä»¥åƒè€ƒç­†è€…çš„ [TGI ä»‹ç´¹æ–‡ç« ](https://ithelp.ithome.com.tw/articles/10332065)ã€‚ (åŒä¸Š)
* æ¨¡å‹é¸æ“‡çš„éƒ¨ä»½ï¼Œå¯ä»¥è€ƒæ…® [Taiwan Llama](https://github.com/MiuLab/Taiwan-LLaMa) ä»¥åŠæœ€è¿‘å‡ºçš„ [CKIP Llama](https://github.com/ckiplab/CKIP-Llama-2-7b) ç­‰æ¨¡å‹ï¼Œå¦å¤–åƒæ˜¯ [Vicuna](https://huggingface.co/lmsys/vicuna-7b-v1.5) ä¹Ÿæ˜¯å¯ä»¥ã€‚
* å› ç‚ºé€™åªæ˜¯å€‹è¶£å‘³æ€§è³ªçš„æ‡‰ç”¨ï¼Œæ‰€ä»¥å°æ¨¡å‹çš„æ•ˆèƒ½æ²’æœ‰å¤ªå¤§çš„è¬›ç©¶ã€‚
* åœ¨ LangChain è£¡é¢ LLM çš„åŸºæœ¬ç”¨æ³•å¦‚ä¸‹ï¼š
    ```python
    from langchain.llms import HuggingFaceTextGenInference
    from langchain.callbacks import StreamingStdOutCallbackHandler

    cb = StreamingStdOutCallbackHandler()

    llm = HuggingFaceTextGenInference(
        inference_server_url="http://localhost:8080/",
        max_new_tokens=64,
        do_sample=True,
        top_k=50,
        top_p=0.95,
        temperature=0.5,
        truncate=512,  # æˆªæ–· 512 Tokens ä»¥å‰çš„è¼¸å…¥
    )

    # llm("### USER: ä»€éº¼æ˜¯èªè¨€æ¨¡å‹ï¼Ÿ\n### ASSISTANT: ", stop=["ï¼Œ"])
    # # Output: 'èªè¨€æ¨¡å‹æ˜¯ä¸€ç¨®äººå·¥æ™ºæ…§æ¨¡å‹'

    llm("### USER: ä»€éº¼æ˜¯èªè¨€æ¨¡å‹ï¼Ÿ\n### ASSISTANT: ", callbacks=[cb])
    ```
    * æ­é… Callback é€²è¡Œ Streaming è¼¸å‡ºï¼Œé€™å€‹ `callbacks` åƒæ•¸å…¶å¯¦ä¹Ÿèƒ½æ”¾åœ¨ LLM åˆå§‹åŒ–è£¡é¢ã€‚

---

## Prompt Template
* åœ¨ LangChain è£¡é¢å¯ä»¥ä½¿ç”¨å„ç¨® Prompt Template é¡åˆ¥ä¾†å°ä¸åŒçš„æ¨£æ¿é€²è¡Œç®¡ç†ï¼Œå…¶ç”¨æ³•å¦‚ä¸‹ï¼š
    ```python
    from langchain.prompts import PromptTemplate

    template = "### USER: {query}\n### ASSISTANT: "
    prompt = PromptTemplate.from_template(template)

    prompt.format(query="ä»€éº¼æ˜¯èªè¨€æ¨¡å‹ï¼Ÿ")
    print(repr(prompt))
    # Output: '### USER: ä»€éº¼æ˜¯èªè¨€æ¨¡å‹ï¼Ÿ\n### ASSISTANT: '
    ```
* ç¶“ç”±æ¨£æ¿ç”¢ç”Ÿçš„æç¤ºï¼Œé›–ç„¶å¯ä»¥ç•¶æˆä¸€èˆ¬å­—ä¸²ä¸Ÿé€² LLM ä½¿ç”¨ï¼Œä½†æ˜¯åœ¨ LangChain è£¡é¢å…¶å¯¦æœ‰æ›´ "**Chain**" çš„åšæ³•ï¼š
    ```python
    from langchain.prompts import PromptTemplate

    template = (
        "### SYSTEM:\nä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚\n\n",
        "### USER:\n{query}\n\n",
        "### ASSISTANT:\n",
    )
    template = PromptTemplate.from_template(template)
    chain = template | llm
    chain.invoke({"query":"ä»€éº¼æ˜¯èªè¨€æ¨¡å‹ï¼Ÿ"})
    # Output: èªè¨€æ¨¡å‹æ˜¯ä¸€ç¨®äººå·¥æ™ºæ…§æ¨¡å‹...
    ```
    * å¾ˆé…·å§ï¼å±…ç„¶ç”¨ OR é‹ç®—å­ `|` ä¾†æè¿°å…ƒä»¶é–“çš„äº’å‹•ï¼Œæ˜¯å€‹éå¸¸ç‰¹åˆ¥çš„åšæ³•ï¼
* å¦‚æœæ˜¯æª¢ç´¢é¡çš„æ‡‰ç”¨ï¼Œé‚£æ¨£æ¿å¯èƒ½æœƒé•·çš„åƒé€™æ¨£ï¼š
    ```python
    template = (
        "### INST: è«‹æ ¹æ“š REF å›ç­” USER çš„å•é¡Œ\n\n",
        "### REF: {reference}\n\n",
        "### USER: {query}\n\n",
        "### ASSISTANT: "
    )
    prompt = PromptTemplate.from_template(template)

    chain = prompt | llm.bind(stop-["###"])

    params = {
        "reference": "å°æ˜æ¯å¤©å¾æ¿æ©‹é€šå‹¤åˆ°æ–°åº—å·¥ä½œ",
        "query": "è«‹å•å°æ˜ä¸‹ç­æœƒå›å»å“ªè£¡ï¼Ÿ",
    }

    chain.invoke(params)
    # Output: å°æ˜å¾æ¿æ©‹é€šå‹¤åˆ°æ–°åº—å·¥ä½œ,å› æ­¤ä¸‹ç­å¾Œä»–å°‡æœƒè¿”å›æ¿æ©‹ã€‚
    ```
    * å…¶å¯¦é€™äº›åŸºæœ¬çš„æç¤ºæ¨£æ¿è·Ÿä¸€èˆ¬çš„æ ¼å¼åŒ–å­—ä¸²ç”¨èµ·ä¾†æ²’ä»€éº¼å¤ªå¤§çš„ä¸åŒï¼Œä½†æ˜¯é€éé€™å€‹é¡åˆ¥å°±èƒ½è·Ÿå…¶ä»–å…ƒä»¶ "Chain" èµ·ä¾†ç”¨ã€‚
* è£œå……ï¼š
    * åœ¨é€™è£¡ `|` æ˜¯ä¸€ç¨® Bitwise Operatorï¼Œæ­¤é‹ç®—å­æœƒåœ¨ä½å…ƒå±¤ç´šé€²è¡Œ OR é‹ç®—ï¼Œä¾‹å¦‚ï¼š
        ```python
        x = 0b1100 | 0b1010
        print(f"0b{x:b}") # Output: 0b1110
        ```
    * åœ¨ Python ä¸­ï¼Œå¯ä»¥å®šç¾©é¡åˆ¥çš„ `_or_` æ–¹æ³•ä¾†è‡ªè¨‚ `|` é‹ç®—çš„è¡Œç‚ºï¼Œä¾‹å¦‚ï¼š
        ```python
        class Hello:
            def init (self, value):
                self.value = value

            def _or_(self, other):
                print (f"or self={self}, other={other}")

            def _repr_(self):
                return f"Hello({self.value})"

        hl = Hello(1)
        h2 = Hello(2)
        h1 | h2 # Output: or self-Hello(1), other-Hello(2)
        ```
    * è€Œåœ¨ LangChain æ¡†æ¶è£¡é¢ `chain = template llm` çš„é€™æ®µæ•˜è¿°ï¼Œå…¶å¯¦æ›´åƒæ˜¯æŒ‡ä»¤æ“ä½œè£¡é¢ Pipeline çš„æ¦‚å¿µï¼Œå°‡å‰è€…çš„å…§å®¹ç•¶ä½œå¾Œè€…çš„è¼¸å…¥ã€‚

---

## Embedding Model
Embedding Model ä¹Ÿæ˜¯ LangChain å¦å¤–ä¸€å€‹æ•´åˆç›¸ç•¶è±å¯Œçš„éƒ¨åˆ†ï¼Œ[å„å¼å„æ¨£çš„ Embedding æ¡†æ¶](https://python.langchain.com/docs/integrations/text_embedding)éƒ½è¢«æ•´åˆåœ¨è£¡é¢äº†ã€‚
* æ ¹æ“šç­†è€…çš„ç¶“é©—ï¼Œåœ¨è·¨èªè¨€ä¸”çŸ­æ–‡æœ¬çš„æª¢ç´¢ä¸Šï¼ŒGoogle çš„ Universal Sentence Encoder æ•ˆæœæ˜¯ä¸éŒ¯çš„ï¼Œè€Œä¸”æ¨¡å‹å°ºå¯¸ä¹Ÿæ¯”è¼ƒå°ï¼Œç›¸ç•¶é©åˆæˆ‘å€‘é€™ç¨®æç¬‘æ‡‰ç”¨ï¼š
    ```python
    from langchain.embeddings import TensorflowHubEmbeddings

    url = (
        "https://tfhub.dev/google/",
        "universal-sentence-encoder/tensorFlow2/",
        "multilingual-large/2"
    )
    embeddings = TensorflowHubEmbeddings(model_url=url)
    ```
* åŸºæœ¬ç”¨æ³•å¤§è‡´å¦‚ä¸‹ï¼š
    ```python
    import numpy as np

    texts = ["dog", "ç‹—", "cat", "è²“"]
    embs = embeddings.embed_documents(texts)
    np.inner(embs, embs)
    ```

---

## Vector Store
æœ‰äº†å‘é‡ä¹‹å¾Œå°±å¯ä»¥å­˜åœ¨å‘é‡å„²å­˜ç©ºé–“è£¡é¢ï¼Œé€™äº›å­˜æ”¾å‘é‡çš„åœ°æ–¹ç¨±ç‚º Vector Storeã€‚
* å…¶ç”¨é€”ä¸åƒ…æ˜¯å­˜æ”¾å‘é‡ï¼Œæ›´é‡è¦çš„åŠŸèƒ½åœ¨æ–¼**å¿«é€Ÿæœå°‹å‘é‡**ã€‚
* ä¾‹å¦‚ Faiss å°±æ˜¯å€‹å¯ä»¥å­˜æ”¾èˆ‡æœå°‹å‘é‡çš„å¥—ä»¶ï¼Œæ­é…å‰›æ‰çš„ Embedding Model ä¸€èµ·ä½¿ç”¨ï¼š
    ```python
    from langchain.vectorstores import FAISS

    texts = ["dog", "ç‹—", "cat", "è²“"]
    faiss_store = FAISS.from_texts(
        texts=texts,
        embedding=embeddings,
    )
    ```
* Vector Store æœƒè‡ªå‹•é€é Embeddings é¡åˆ¥å°‡æ–‡å­—è½‰ç‚ºå‘é‡ä¸¦å­˜èµ·ä¾†ï¼Œé€™æ¨£å°±å¯ä»¥ç›´æ¥æŸ¥è©¢ä¸¦å–å¾—èªæ„ç›¸ä¼¼çš„çµæœï¼š
    ```python
    results = faiss_store.search(
        query="ê³ ì–‘ì´",  # éŸ“æ–‡çš„ã€Œè²“ã€
        search_type="similarity",
        k=2,  # å–å…©ç­†çµæœ
    )

    for res in results:
        print(res.page_content)

    # Outputs: è²“, cat
    ```
    * åƒæ•¸ `k` ç”¨ä¾†æŒ‡å®šç³»çµ±è¦æœå°‹å¹¾ç­†çµæœï¼Œç„¶å¾Œ Faiss å°±æœƒä¾ç…§ç›¸ä¼¼åº¦æ’åºä¸¦å›å‚³çµæœã€‚
    * èªªåˆ°æœå°‹å°±è¦æä¸€ä¸‹æˆ‘å€‘çš„è€æœ‹å‹ BM25 å¥½å¤¥ä¼´ï¼š
        ```python
        from langchain.retrievers import BM25Retriever

        bm25 = BM25Retriever.from_texts(texts)
        bm25.get_relevant_documents("cat")
        ```
* åœ¨ LangChain è£¡é¢ BM25 å±¬æ–¼ Retrieverï¼Œè€Œ Faiss å±¬æ–¼ VectorStoresï¼Œä½†å…©è€…éƒ½å…·æœ‰æœå°‹çš„åŠŸèƒ½ã€‚è©²å¦‚ä½•ä¸€èµ·ä½¿ç”¨å‘¢ï¼Ÿ
    * é€™æ™‚å¯ä»¥é€é `EnsembleRetriever` é¡åˆ¥ä¾†è™•ç†ï¼Œé¦–å…ˆéœ€è¦å…ˆå°‡ Falss è½‰æ›æˆ `Retriever` é¡åˆ¥ï¼š
        ```python
        faiss = faiss_store.as_retriever()
        ```
    * ç„¶å¾Œå†å°‡ BM25 èˆ‡ Faiss ä¸€èµ·ä¸Ÿé€² Ensemble è£¡é¢ï¼š
        ```python
        from langchain.retrievers import EnsembleRetriever

        ensemble = EnsembleRetriever(
            retrievers=[faiss, bm25],
            weights=[0.75, 0.25]
        )

        ensemble.get_relevant_documents("ê³ ì–‘ì´")
        ```
    * é€™æ¨£åœ¨æœå°‹æ™‚å°±å¯ä»¥åŒæ™‚åƒè€ƒå…©ç¨®æª¢ç´¢ç³»çµ±çš„çµæœäº†ã€‚
* Vector Store çš„ç¨®é¡ç›¸ç•¶ç¹å¤šï¼Œè«‹æ ¹æ“šè‡ªèº«æ‡‰ç”¨çš„å ´æ™¯åšé¸æ“‡ã€‚å› ç‚ºç­†è€…çš„è³‡æ–™å…¶å¯¦æ²’å¾ˆå¤šï¼Œæ‰€ä»¥é€™å€‹æ‡‰ç”¨åªéœ€è¦ Faiss å°±è¶³å¤ äº†ã€‚

---

## Few-Shot Prompt Template
åœ¨é€™å€‹æ‡‰ç”¨è£¡é¢æœƒä½¿ç”¨åˆ° Few-Shot çš„æŠ€å·§ä¾†å»ºç«‹å®Œæ•´çš„æç¤ºï¼Œå› æ­¤éœ€è¦ç”¨åˆ° `FewShotPromptTemplate` é¡åˆ¥ã€‚
* åœ¨ä½¿ç”¨æ­¤é¡åˆ¥ä¹‹å‰ï¼Œéœ€è¦ä½¿ç”¨åŸºæœ¬çš„æç¤ºæ¨£æ¿ä¾†å®šç¾©æ¯å€‹ç¯„ä¾‹çš„æ ¼å¼ï¼š
    ```python
    examples = [
        {"source": "hello", "target": "å“ˆå›‰"},
        {"source": "goodbye", "target": "å†è¦‹"},
    ]

    example_prompt = PromptTemplate(
        input_variables=["source", "target"],
        template="Source: {source}\nTarget: {target}",
    )

    print(example_prompt.format(**examples[0]))

    """
    Source: hello
    Target: å“ˆå›‰
    """
    ```
* æ¥è‘—ä»¥é€™å€‹æ¨£æ¿ç‚ºåŸºç¤ä¾†å»ºç«‹ Few-Shot Prompt Template çš„å…§å®¹ï¼š
    ```python
    from langchain.prompts.few_shot import FewShotPromptTemplate

    prompt = FewShotPromptTemplate(
        examples=examples,
        example_prompt=example_prompt,
        prefix="è«‹å°‡ä»¥ä¸‹å–®å­—ç¿»è­¯æˆä¸­æ–‡",
        suffix="Source: {input}\nTarget: ",
        example_separator="\n===\n",
        input_variables=["input"],
    )

    print(prompt.format(input="Starburst Stream"))
    ```
    * è¼¸å‡ºçµæœï¼š
    ```
    è«‹å°‡ä»¥ä¸‹å–®å­—ç¿»è­¯æˆä¸­æ–‡
    ===
    Source: hello
    Target: å“ˆå›‰
    ===
    Source: goodbye
    Target: å†è¦‹
    ===
    Source: Starburst Stream
    Target:
    ```
    * é€™æ¨£å°±å®Œæˆ Few-Shot Prompt Template çš„è¨­å®šå›‰ï¼

---

## Example Selector
æˆ‘å€‘å·²ç¶“çŸ¥é“å¦‚ä½•å°‡ Prompt èˆ‡LLMä¸²åœ¨ä¸€èµ·äº†ï¼Œç¾åœ¨éœ€è¦ç…©æƒ±çš„éƒ¨ä»½æ˜¯`ä½¿ç”¨è€…è¼¸å…¥ => æª¢ç´¢ => å°‘é‡æ¨£æœ¬æç¤º`é€™æ®µæµç¨‹è©²å¦‚ä½•ä¸²æ¥èµ·ä¾†ã€‚
* é€™è£¡å°±è¦å‡ºå‹• Example Selector ä¾†å¹«å¿™ï¼š
    ```python
    import json

    from langchain.prompts.example_selector import (
        SemanticSimilarityExampleSelector as Selector
    )
    from langchain_community.embeddings import TensorflowHubEmbeddings
    from langchain_community.vectorstores import FAISS

    with open("datasets.json", "rt", encoding="UTF-8") as fp:
        datasets: dict[str, str] = json.load(fp)

    url = (
        "https://www.kaggle.com/models/google/",
        "universal-sentence-encoder/tensorFlow2/",
        "multilingual-large/2"
    )
    embeddings = TensorflowHubEmbeddings(model_url=url)

    example_selector = Selector.from_examples(
        examples=datasets,
        embeddings=embeddings,
        vectorstore_cls=FAISS,
        k=10,
    )
    ```
* Example Selector æŠŠæå–å’Œå­˜æ”¾å‘é‡çš„å‹•ä½œéƒ½å°è£èµ·ä¾†äº†ï¼ŒæŸ¥è©¢æ–¹æ³•å¦‚ä¸‹ï¼š
    ```python
    result = example_selector.select_examples({"query": "Dark"})
    print(result)

    """
    æŸ¥è©¢çµæœï¼š
    [{'source': 'Darkness Rise', 'target': 'æš—å´›'},
     {'source': 'Dark Matter', 'target': 'é»‘æš—ç‰©è³ª'},
     {'source': 'Looming Darkness', 'target': 'é—‡é»‘è¿«è¿‘'},
     {'source': 'Dark Binding', 'target': 'æš—å½±ç¦éŒ®'},
     {'source': 'Shroud of Darkness', 'target': 'å¤œå¹•åº‡è­·'},
     {'source': 'Dark Sphere', 'target': 'é»‘æš—æ˜Ÿé«”'},
     {'source': 'Black Shield', 'target': 'é»‘æš—ä¹‹ç›¾'},
     {'source': 'Dark Passage', 'target': 'é¬¼å½±ç‡ˆç± '},
     {'source': 'Shadow Dash', 'target': 'å½±è¥²'},
     {'source': 'Piercing Darkness', 'target': 'åˆºéª¨å¹½é—‡'}]
    """
    ```
    * OKï¼Œåˆ°é€™é‚Šè¬äº‹ä¿±å‚™åªæ¬ æ±é¢¨ï¼Œæ¥ä¸‹ä¾†å°±è¦çœ‹çœ‹å¦‚ä½•å°‡é€™äº›å…ƒä»¶å…¨éƒ¨ Chain åœ¨ä¸€èµ·å•¦ï¼

---

## Chain !
è®€å–è³‡æ–™é›†çš„éƒ¨ä»½èˆ‡ä¸Šå€‹å°ç¯€æä¾›çš„ç¨‹å¼ç¢¼æ˜¯ä¸€æ¨£çš„ï¼Œé€™è£¡ä¸å†é‡è¤‡ä¸€æ¬¡ã€‚
* è®€å–å®Œè³‡æ–™é›†ä¹‹å¾Œï¼Œå°±è¦ä¾†å»ºç«‹æ¨£æ¿ï¼š
    ```python
    from langchain.prompts import PromptTemplate
    from langchain.prompts.few_shot import FewShotPromptTemplate

    # å»ºç«‹ Example Template
    example_prompt = PromptTemplate(
        input_variables=["source", "target"],
        template="Source: {source}\nTarget: {target}",
    )

    # å»ºç«‹ Few-Shot Template
    prompt = FewShotPromptTemplate(
        example_selector=example_selector,
        example_prompt=example_prompt,
        suffix="Source: {query}\nTarget: ",
        prefix="è«‹æ ¹æ“šä»¥ä¸‹ç¯„ä¾‹ï¼Œç”¢ç”Ÿä¸€å€‹ä¸­äºŒçš„æŠ€èƒ½ç¿»è­¯ã€‚",
        input_variables=["query"],
    )
    ```
* æœ€å¾ŒæŠŠLLMä¸²ä¸Šå»ï¼š
    ```python
    from langchain_openai import OpenAI

    llm = OpenAI(
        api_key="auth-token-ouo123",
        model="meta-llama/Meta-Llama-3-8B-Instruct",
        base_url="http://localhost:8000/v1",
    )

    chain = prompt | llm.bind(stop=["\n"]) # é‡åˆ°æ›è¡Œåœæ­¢ç”Ÿæˆ
    print(chain.invoke("Starburst Stream"))
    ```
* é †ä¾¿ä½¿ç”¨ Gradio å»ºç«‹ä¸€å€‹ç°¡å–®çš„ Demo ç¶²é ï¼š
    ```python
    import gradio as gr

    def send(source):
        return chain.invoke({"query": source})

    with gr.Blocks() as app:
        source = gr.Textbox(label="Source")
        target = gr.Textbox(label="Target")
        source.submit(send, source, target)
    app.launch()
    ```
* æ•´å€‹æ‡‰ç”¨ä½¿ç”¨èµ·ä¾†çš„æ•ˆæœå¦‚ä¸‹ï¼š
    ![ä¸­äºŒæŠ€èƒ½ç¿»è­¯ä½¿ç”¨ç¯„ä¾‹](images/ä¸­äºŒæŠ€èƒ½ç¿»è­¯ä½¿ç”¨ç¯„ä¾‹.png)
* ğŸ“ ç¯„ä¾‹ç¨‹å¼ç¢¼
    * [ç­†è€…ç¨‹å¼ç¢¼](https://tinyurl.com/llm-note-13)
    * è‡ªå·±å˜—è©¦: .../LLM/project/langchain

---

## é€£çµ
* [LangChain](https://www.langchain.com/)
* [GitHub: LangChain](https://github.com/langchain-ai/langchain)
* [LangChain: Few-Shot Prompt](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/few_shot_examples)
* [LangChain: Debugging](https://python.langchain.com/docs/modules/chains/how_to/debugging)
* [LangChain: BM25](https://python.langchain.com/docs/integrations/retrievers/bm25)
* [LangChain: QA Retriever](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa)

---

## çµè«–
* LangChain é€™å€‹æ¡†æ¶çš„ç¢ºå°‡èªè¨€æ¨¡å‹æ‡‰ç”¨ä¸­çš„æ¯å€‹å…ƒä»¶èˆ‡è¡Œç‚ºéƒ½å°è£çš„å¾ˆå¥½ï¼Œè€Œä¸”ä½¿ç”¨äº†ç›¸ç•¶æœ‰è¶£çš„ Chain æ¦‚å¿µä¾†å°‡å…ƒä»¶ä¸²è¯èµ·ä¾†ï¼Œæ˜¯å€‹éå¸¸ç¨ç‰¹çš„æ€ç¶­ã€‚
* å¹¸å¥½ LangChain çœŸçš„å¾ˆç°¡å–®å¥½ä¸Šæ‰‹ï¼Œæ‰æ²’è®“ç­†è€…åœ¨é€™ç¯‡æ–‡ç« é–‹å¤©çª—ã€‚
* LangChain çš„æ˜“ç”¨æ€§èˆ‡éˆæ´»æ€§åŠ ä¸Šæ´»èºçš„ç¤¾ç¾¤ï¼Œæœªä¾†ç™¼å±•ç›¸ç•¶å€¼å¾—é—œæ³¨ï¼
* å…¶ä»–å€¼å¾—åƒè€ƒçš„æ‡‰ç”¨æ¡†æ¶åŒ…å« [Guidance](https://github.com/guidance-ai/guidance), [LMQL](https://lmql.ai/), [Semantic Kernel](https://github.com/microsoft/semantic-kernel) ç­‰ç­‰ï¼Œçµ¦å¤§å®¶åƒè€ƒã€‚

---