# 任務導向聊天機器人 (TOD Chatbot)
* **任務導向對話 (Task-Oriented Dialogue, TOD)** 聊天機器人，與一般的聊天機器人有什麼不同呢？
    * 任務導向代表這段對話有**明確的任務目標**，例如餐廳點餐、飛機訂票或飯店預約等等。
    * 雖然ChatGPT已經是個很強大的語言模型，有豐富的知識問答與流暢的文字生成，但要達成長流程的任務對話，其實還是有一些困難需要克服的。
* 傳統上想要製作一個任務導向的聊天機器人，可以使用 [Google Dialogflow](https://cloud.google.com/dialogflow) 、 [Microsoft Bot Framework](https://dev.botframework.com/) 、 [Amazon Lex](https://aws.amazon.com/tw/lex/) 等等的服務，這些服務提供使用者友善的介面，無論會不會寫程式都很適合操作。
* 但如果你特別喜歡寫程式，想從底層技術面親身感受 TOD 的魅力，那 [Rasa](https://rasa.com/) 是個不錯的選擇。
* 補充：
    * 在接觸這類聊天機器人的過程中，可能會去研究 Google 的 Dialogflow 框架，雖然這個框架主要還是使用傳統 BERT 模型建立的，但因為功能已經相當完整，所以依然是個入門不錯的選擇。
    * 而 Dialogflow 其實還區分成兩種版本：
        * [ES](https://cloud.google.com/dialogflow/es/docs)：是比較簡單的版本。
        * [CX](https://cloud.google.com/dialogflow/cx/docs)：是比較複雜的版本。
    * 如果是沒有接觸過 TOD 系統的讀者，可以考慮先從 ES 版開始著手學習，才不會被 CX 版那複雜的文件天書給嚇到。

---

## 任務導向到底是什麼呢？
任務導向對話與一般對話最大的區別，在於系統需要**從對話裡面擷取實體資訊**出來使用。
* 例如一個查詢天氣的機器人，就會需要知道使用者想查的是氣溫、 降雨機率還是空氣品質？要查詢哪個時間、哪個地方的天氣呢？
* 系統可能會進行以下分析：
    ```
    User: 明天會下雨嗎？
    Slots:
      - Date: 明天
      - QueryType: 降雨機率

    Bot: 請問要查詢哪個地方的降雨機率？
    User: 新店
    Slots:
      - Location: 新北市新店區
    ```
* 系統取得日期、時間與查詢種類這些**實體資訊 (Entity)** 後，就能用來建構查詢天氣所需要的參數，例如發一個 HTTP Request API 出去：
    ```!
    https://www.weather-api.example/query?date=明天&location=新北市新店區&query_type=降雨機率
    
    # https://weather.example/query?date=20231007&location=taipei&query_type=rainy_probability
    ```
* 從上面的範例可以看到，當系統缺乏位置資訊時，會對使用者做進一步的追問，這便是任務導向系統能根據**對話狀態 (State)** 做**流程決策 (Policy)** 的能力。
    * 這時你可能會想，我好像在某些 GPTs 看過類似的事情欸？
        * 這些應用的確屬於廣義上的任務導向對話，因為對這些應用來說，他們都有個特定的目標需要執行，且完成這個任務所需的資訊，必須從使用者的對話中取得。
    * 多數情況下，一般的對話應用通常都在做**單輪對話**的任務，而任務導向對話更著重在多輪對話上，有時甚至是數十回合以上非常冗長的對話，即便現在有很多模型已經支援到 100K 以上的輸入，但是這類模型很容易發生**迷途 (Lost in the Middle)** 的問題。
    * 因此在任務導向系統裡面，通常會額外維護一份**記憶狀態**來追蹤目前對話的進度。
* 所以任務導向對話系統主要著重在三個面向：
    * **實體擷取**
    * **決策流程**
    * **記憶狀態**
* 補充：
    * 另外像是生成自然回覆也算是對話系統會探討的議題，雖然現在的語言模型可以產生自然流暢的文字，但是在一些較為嚴謹的商用情境下，開發者可能會更傾向於使用定型範本進行回覆，尤其是當系統應用涉及金流時更是需要注意，如果模型在描述數字時多一個零或少一個零的話就虧大了！

---

## 有了 LLM 的TOD 系統天下無敵？
首先關注 [**Are LLMs All You Need For TOD**](https://arxiv.org/abs/2304.06556) 這篇論文，是基於指令微調語言模型的做法，其概念相當簡單。
* 傳統對話系統會有**領域分類器 (Domain Classifier)**、 **狀態追蹤器 (State Tracker)** 與**回覆產生器(Response Generator)** 等模組，作者要求語言模型分別扮演這三個角色來進行對話，例如：
    ```!
    請根據以下對話狀態，決定這是什麼領域。請從以下清單選擇一個領域回答：餐廳、飯店、景點、計程車和火車。只需要回覆答案即可，並從清單中選擇最有可能的答案。  
    
    === 範例 1 ===
    使用者：我要找一間便宜的餐廳
    機器人：我們有很多種便宜的餐廳，請問您對哪種餐廳有興趣呢？
    使用者：中式餐廳
    領域：餐廳
    
    === 範例 2 ===
    使用者：我要訂兩點的車票
    機器人：請問你要從哪裡出發？
    使用者：板橋
    領域：火車
    
    ===
    現在完成以下範例：
    使用者：我想要在北部找一個便宜的住宿地點
    領域：
    ```
    * 將以上提示輸入到 ChatGPT 就能輕鬆獲得「飯店」這個答案，這就是個非常經典的少量樣本提示技巧。
* 類似的概念也能應用在狀態追蹤器上：
    ```!
    請根據對話的最後一句辨識相關實體，以「實體：值」的格式呈現，其中冒號和值之間不應有空格。 使用分號(;)分隔不同的實體資訊。如果未指定，則留空該值。應捕捉的值包括：

    - 價格：飯店的價格
    - 區域：指定飯店所在的區域 (東、南、西、北、中)
    - 網路：指定飯店是否有網路 (是、否)
    - 停車場：指定飯店是否有停車場 (是、否)
    - 星級：指定飯店的星級數 (一、二、三、四、五)
    - 類型：指定飯店的類型 (飯店、民宿、附早餐)

    === 對話 ===
    使用者：我想要在北部找一個便宜的住宿地點
    實體：
    ```
    * 輸入這段提示就能獲得「區域：北；價格：便宜」的結果，這裡使用的是零樣本提示，因此必須對每個實體進行詳細說明，並列舉可能的值。
* 最後的回覆產生器也是相同的原理：
    ```!
    你現在是個負責預約酒店的客服人員，使用者可以根據酒店名稱、地區、停車場、網路可用性或價格來查詢酒店，請根據資料庫的查詢結果進行回覆。

    === 對話 ===
    使用者：我想要在北部找一個便宜的住宿地點
    狀態：飯店；區域：北；價格：便宜
    查詢結果：酒店數量 23 家
    回覆：
    ```
    * 將以上提示丢入ChatGPT後得到以下回覆：
    ```!
    您好！在北部地區，我為您找到了 23 家價格較為便宜的酒店。請問您需要我列出其中幾家供您參考，或是有其他特定的需求嗎？
    ```
    * 透過簡單的零樣本或少量樣本提示的技巧，就能建構起一個基於大型語言模型的任務導向對話系統了！
    * 這樣的做法不只對 ChatGPT 有用，在一些參數量較小的語言模型上也能見效。
* 筆者使用 Llama 3 8B 進行實測，在領域分類上看起來尚可，但狀態追蹤上錯誤率就滿高了，而且產生回覆的部份很容易幻想出許多額外資訊：
    ```!
    我們找到 23 家便宜的酒店在北部地區。以下是一些選擇：
    * 北區的「晨曦酒店」提供每晚 NT$1,200 的優惠價格。
    *「北方酒店」位於北區，提供每晚 NT$1,500 的優惠價格。
    *「農曬商務酒店」位於北區，提供每晚 NT$1,800 的優惠價格。

    請選擇您喜歡的酒店，我們將幫您預約。
    ```
    * 但事實上給模型的提示裡面根本沒有這些資訊，看來我們的 TOD 系統距離天下無敵還有一段距離。
* 圖源：[Are LLMs All You Need For TOD?](https://arxiv.org/abs/2304.06556)
    ![A detailed description of our proposed pipeline](images/A%20detailed%20description%20of%20our%20proposed%20pipeline.png)

---

## Rasa
[Rasa](https://github.com/RasaHQ/rasa) 是個開源的聊天機器人開發框架，在 [GitHub](https://github.com/RasaHQ/rasa/graphs/contributors) 上可以看到這是個從 2016 年發起的專案，算是有一定年紀的框架了，但 Rasa 直到現在都還是非常活躍，而最近能夠從[官方文件](https://tinyurl.com/llm-rasa)上看到一些與語言模型整合的蛛絲馬跡，雖然看起來應該是付費版會員的功能，但是從這些說明文件中，還是可以推敲其運作原理。
* 在官方文件上的架構圖，與方才介紹的論文是有些異曲同工之妙的，他們同樣使用了基於檢索的方法來建構提示，同樣藉由語言模型能處理少量樣本提示的能力來進行各個階段的辨識。
* Rasa 意圖分類器架構圖：

    (中文版)
    ![Rasa 意圖分類器架構圖 (中文版)](images/Rasa%20意圖分類器架構圖%20(中文版).png)

    [(官方版)](https://legacy-docs-oss.rasa.com/docs/rasa/next/llms/llm-intent)
    ![Rasa 意圖分類器架構圖](images/Rasa%20意圖分類器架構圖.png)
    
* 以下是意圖分類的提示範例：
    ```!
    請分類使用者輸入的意圖，只需要回覆意圖名稱即可。
    意圖必須是以下其中一個：
    - 確認
    - 問候

    訊息：哈囉
    意圖：問候

    訊息：是的我是
    意圖：確認

    訊息：你好啊
    意圖：
    ```
    * 同樣也是一段指令搭配少量樣本，然後請語言模型回答分類結果，其實與上個小節的方法大同小異。
* 但是在生成回覆的部份，[Rasa 的做法](https://rasa.com/docs/rasa/next/llms/llm-nlg)就比較不一樣了：
    ```!
    以下是一段與 AI 助理的對話。
    這位助理非常有幫助、創意十足、 聰明伶俐且十分友善。
    請重新改寫建議的 AI 助理回應，必須與原始訊息相近且保留其意義。

    先前與使用者的對話如下：
    使用者：我想要在北部找一個便宜的住宿地點

    建議的 AI 回覆：在北部找到便宜的酒店有23家
    改寫的 AI 回覆：
    ```
    * 將以上提示輸入 Llama 3 8B 得到的結果：
    ```!
    北部有很多便宜的住宿選擇！根據您的需求，我可以推薦 23 家酒店，價格相對較低。您可以根據自己的喜好和預算選擇合適的住宿。
    ```
    * 跟前一個做法比起來，這個結果令人滿意多了！
* 開發者預先設定好一個定型範本，再請語言模型進行改寫，這樣就比較不容易產生錯誤或幻覺了。因此不管是少量樣本提示或定型範本改寫，其核心思想都是要給語言模型一個參考的基準。
* 有趣的是 Rasa 提出了另外一種 [Intentless Policy](https://tinyurl.com/llm-intentless) 的做法，所謂的**決策 (Policy)** 是指負責系統根據**對話狀態 (State)** 判斷需要採取什麼**動作 (Action)** 的模組。
    * 例如現在使用者在打招呼，那決策模組就會決定回覆使用者一個打招呼的訊息。如果使用者說要下一個訂單，那決策模組就會決定呼叫一個 API 把訂單存進資料庫等等。
* 多數的情況都可以透過規則式決策來處理，但最麻煩的是出現一些系統意料之外的狀況，這時系統到底該如何做回應呢？
    * 這裡可以分成兩個部份：
        1. 第一個是系統如何**偵測**意料之外的情況發生了
        2. 第二個就是如何**應對**這個意料之外的情況
* 僅透過 Rasa 的介紹並沒有辦法很明確的知道 Intentless Policy 到底是如何跟語言模型進行互動的，但是從 Rasa 提供的[範例專案](https://github.com/RasaHQ/starter-pack-intentless-policy)可以猜出一些蛛絲馬跡。
    * 首先是這個範例的意圖辨識部份幾乎沒有特別重要的範例，只包含了一些打招呼之類的意圖而已，整個系統都是倚賴「劇本機制」來處理大部分的對話流程。
    * 再來觀察官方文件提供的範例： 

    (中文版)
    ![Rasa 官方範例圖中文版](images/Rasa%20官方範例圖中文版.png)

    [(官方版)](https://legacy-docs-oss.rasa.com/docs/rasa/next/llms/llm-intentless/)
    ![Rasa 官方範例圖](images/Rasa%20官方範例圖.png)

* 可見這個 Intentless Policy 功能主打**語境回應 (Contextual Response)** 的特性，需要根據上下文的語境來判斷使用者當前的意圖，因此推測可能的做法是將前幾回合的對話內容放進提示，請語言模型判斷應該如何回覆。
* 另外官方文件也有提到，這個功能並不會生成新的回覆，也就是說回覆都是從預先定義好的句子裡面挑選的，所以筆者對整個提示的臆測大致如下：
    ```
    你是一個專業的銀行客服，請根據對話內容挑選適當的回覆，只要回覆選項即可。

    回覆 A：您可以使用手機 App 進行匯款。
    回覆 B：您可以攜帶雙證件與存簿臨櫃辦理。
    回覆 C：很抱歉，我幫不上忙。

    === 範例 1 ===
    使用者：有沒有零手續費的匯款方式
    機器人：回覆 A

    === 範例 2 ===
    使用者：我沒有手機該如何匯款
    機器人：回覆 B

    === 對話 ===
    使用者：匯款可不可以不要手續費
    機器人：回覆 A
    使用者：可是我手機壞了
    機器人：
    ```
    * 把以上提示丟進 ChatGPT 或 Llama 3 8B 做測試，都可以獲得「回覆B」的答案，因此看起來這套做法是可行的。
    * 根據官方文件所述，這應該是個開源的功能，所以實際的提示到底如何建構也無從得知，這裡筆者只是提供一個方向給大家參考。
* 補充：
    * Rasa 的樣板與 Hugging Face 的分詞器一樣使用的是 [Jinja](https://jinja.palletsprojects.com/en/3.0.x/) 套件喔！
* 在大型語言模型出現之前，Rasa 就已經是個發展成熟的框架了，基本元件使用起來相當靈活，官方文件的內容相當詳細且豐富，也有進一步的商業版可用。
    * 現在加入強大的大型語言模型之後更是錦上添花，辨識率、跨語言等都不再是令人頭大的問題後，開發者進行對話的調試效率會更加提昇，在任務導向對話這方面的發展未來可期。

---

## 連結
* [arXiv Paper: Are LLMs All You Need For TOD?](https://arxiv.org/abs/2304.06556)
* [Rasa Documentation](https://rasa.com/docs/)
* [Google Dialogflow](https://cloud.google.com/dialogflow)

---

## 結論
* 相較於大型語言模型的蓬勃發展，任務導向對話系統的實際應用相對少了點。
* 但無論是學界還是業界，都不斷提出基於語言模型的做法，而且核心概念其實都很相似：
    * 透過指令要求語言模型扮演某個傳統元件，並結合檢索模型來取代傳統的訓練步驟，所以無需訓練，加上語言模型本身的泛用性且跨語言的特質，使原本有些瓶頸的任務導向對話系統看見了相當明亮的未來！
* 有沒有發現最近幾個章節三句不離檢索一詞！
    * 筆者認為，即便未來語言模型再也沒有輸入上限問題，檢索方法依然會相當受用，因為與檢索結合的方法不僅能縮短提示、減少運算量，還能讓模型產生更精確的回覆，相信資訊檢索這領域會再次得到高度的重視。

---