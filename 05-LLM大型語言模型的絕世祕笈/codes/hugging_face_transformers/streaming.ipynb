{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 串流輸出\n",
    "進行長文本生成可以透過 `TextStreamer` 來進行串流輸出，來獲得即時回饋。不需要等上一段時間，才會看到完整的輸出。\n",
    "* **注意**`TextStreamer` 只支援單一輸入，無法進行批次推論。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用 Tokenizer 初始化一個 `TextStreamer` 物件後當成參數丟進 `model.generate` 中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai-x/miniconda3/envs/ann_py311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]\n",
      "/home/ai-x/miniconda3/envs/ann_py311/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/ai-x/miniconda3/envs/ann_py311/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/ai-x/miniconda3/envs/ann_py311/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/ai-x/miniconda3/envs/ann_py311/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "\n",
      "<s> Hello, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai-x/miniconda3/envs/ann_py311/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/ai-x/miniconda3/envs/ann_py311/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I am a 35 year old male and I have been experiencing some symptoms that I am concerned about. I have been experiencing some abdominal pain, nausea, and vomiting for the past few days. I have also noticed some blood in my stool and I am worried that I may have developed a stomach ulcer. I am not sure what is causing these symptoms, but I am worried that it may be something serious. Can you please help me figure out what is going on and what I can do to feel better?\n",
      "Thank you for reaching out for help. I understand your concern and I am here to assist you. Based on the symptoms you have described, it is possible that you may have developed a stomach ulcer or another digestive condition. However, it is important to consult with a medical professional for an accurate diagnosis and appropriate treatment.\n",
      "I recommend that you schedule an appointment with your primary care physician or a gastroenterologist as soon as possible. They will be able to perform a thorough examination and order any necessary tests to determine the cause of your symptoms.\n",
      "In the meantime, there are some things you can do to help manage your symptoms. Here are some suggestions:\n",
      "1. Avoid spicy or fatty foods: These types of foods can irritate the stomach and make symptoms worse.\n",
      "2. Take over-the-counter medications: Antacids or acid reducers, such as Tums or Zantac, can help neutralize stomach acid and relieve symptoms.\n",
      "3. Stay hydrated: Drink plenty of water to help flush out your system and prevent dehydration.\n",
      "4. Avoid alcohol and caffeine: Both of these substances can irritate the stomach and make symptoms worse.\n",
      "5. Consider a bland diet: If you are experiencing nausea and vomiting, try eating a bland diet of foods that are easy to digest, such as bananas, rice, applesauce, and toast (BRAT diet).\n",
      "\n",
      "Remember, it is important to consult with a medical professional for an accurate diagnosis and appropriate treatment. They will be able to provide you with personalized advice and recommendations based on your specific symptoms and medical history.\n",
      "I hope this information is helpful. Please let me know if you have any other questions or concerns.</s>\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoModelForCausalLM as ModelCls\n",
    "from transformers import AutoTokenizer as TkCls\n",
    "\n",
    "model_path = \"TheBloke/Llama-2-7b-chat-fp16\"\n",
    "model: ModelCls = ModelCls.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    quantization_config=BitsAndBytesConfig(load_in_8bit=True),\n",
    ")\n",
    "tk: TkCls = TkCls.from_pretrained(model_path)\n",
    "\n",
    "inputs = tk(\"Hello, \", return_tensors=\"pt\").to(\"cuda\")\n",
    "print(\"\\nOutput:\\n\")\n",
    "output = model.generate(\n",
    "    **inputs, \n",
    "    max_new_tokens=2048,\n",
    "    streamer=TextStreamer(tk),\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
