{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "768cde92",
   "metadata": {},
   "source": [
    "### Quanto\n",
    "[Quanto](https://github.com/huggingface/optimum-quanto) 是由 Hugging Face 所開發的量化套件，支援 FP8、INT8、INT4、 INT2 等量化層級。\n",
    "* 屬於**訓練後量化 (Post-Training Quantization, PTQ)**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef847a8",
   "metadata": {},
   "source": [
    "#### 1. 首先安裝套件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d1744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install quanto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bac1643",
   "metadata": {},
   "source": [
    "#### 2. 透過 QuantoConfig 類別來對模型進行量化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d089b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM\n",
    "from transformers import QuantoConfig\n",
    "\n",
    "#可以是 int2, int4, int8, float8\n",
    "quanto_config = QuantoConfig(weights=\"int4\")\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    device=\"auto\",\n",
    "    quantization=quanto_config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
