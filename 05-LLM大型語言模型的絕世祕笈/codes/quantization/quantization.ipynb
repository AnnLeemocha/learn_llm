{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7fa4ba2",
   "metadata": {},
   "source": [
    "### 透過 Python 簡單實做這種量化方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c821f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10db53ac",
   "metadata": {},
   "source": [
    "#### FP16 to Int8 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc12c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "#     fp16_weights   -   FP16 權重\n",
    "# Output\n",
    "#     int8_weights   -   INT8 權重\n",
    "#     scale          -   縮放係數\n",
    "def quantize_fp16_to_int8(fp16_weights):\n",
    "    # 找到權重的絕對最大值\n",
    "    abs_max_val = np.max(np.abs(fp16_weights))\n",
    "\n",
    "    # 計算縮放係數 Scaling Factor\n",
    "    scale = 127 / abs_max_val\n",
    "\n",
    "    # 將 FP16 權重轉換為 INT8\n",
    "    weights = fp16_weights * scale\n",
    "    int8_weights = np.round(weights).astype(np.int8)\n",
    "\n",
    "    return int8_weights, scale\n",
    "\n",
    "# Input\n",
    "#     int8_weights   -   INT8 權重\n",
    "#     scale          -   縮放係數\n",
    "# Output\n",
    "#     fp16_weights   -   FP16 權重\n",
    "def dequantize_int8_to_fp16(int8_weights, scale):\n",
    "    # 將 INT8 權重轉換回 FP16\n",
    "    return int8_weights.astype(np.float16) / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f892a1d",
   "metadata": {},
   "source": [
    "轉換並觀察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632a8c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original FP16 Weights: [ 1.    -0.5    0.25  -0.125]\n",
      "Int8 Weights: [127 -64  32 -16]\n",
      "Quantization Constant: 127.0\n",
      "Reconstructed FP16 Weights: [ 1.    -0.504  0.252 -0.126]\n",
      "Original Output: 0.875\n",
      "Quantized Output: 0.8740234375\n",
      "Output Loss: 0.0009765625\n"
     ]
    }
   ],
   "source": [
    "# 假設我們有一組 FP16 權重\n",
    "w_fp16 = np.array([1.0, -0.5, 0.25, -0.125], dtype=np.float16)\n",
    "print(f\"Original FP16 Weights: {w_fp16}\")\n",
    "\n",
    "# 量化 FP16 權重到 INT8\n",
    "w_int8, sf = quantize_fp16_to_int8(w_fp16)\n",
    "print(f\"Int8 Weights: {w_int8}\")\n",
    "print(f\"Quantization Constant: {sf}\")\n",
    "\n",
    "# 從 Int8 權重重建 FP16 權重\n",
    "rw_fp16 = dequantize_int8_to_fp16(w_int8, sf)\n",
    "print(f\"Reconstructed FP16 Weights: {rw_fp16}\")\n",
    "\n",
    "# 觀察輸出差異\n",
    "x = np.array([1.0, 0.25, -0.5, -1.0])   # x         輸入向量，模擬模型的輸入資料（可以想像是一層神經元的輸入）\n",
    "y = np.matmul(x, w_fp16)                # w_fp16    原始 FP16 權重（高精度）\n",
    "                                        # y\t        使用原始權重計算的輸出（理論上是最準確的）\n",
    "qy = np.matmul(x, rw_fp16)              # rw_fp16   量化再反量化後的權重（從 INT8 還原回來，低精度）\n",
    "                                        # qy\t    使用量化重建權重計算的輸出（可能有誤差）\n",
    "loss = y - qy                           # loss\t    兩者之間的差（代表量化導致的輸出誤差）\n",
    "\n",
    "print(f\"Original Output: {y}\")\n",
    "print(f\"Quantized Output: {qy}\")\n",
    "print(f\"Output Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd1644",
   "metadata": {},
   "source": [
    "#### FP16 to Int4 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4dbc624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "#     fp16_weights   -   FP16 權重\n",
    "# Output\n",
    "#     int4_weights   -   INT4 權重\n",
    "#     scale          -   縮放係數\n",
    "def quantize_fp16_to_int4(fp16_weights):\n",
    "    # 找到權重的絕對最大值\n",
    "    abs_max_val = np.max(np.abs(fp16_weights))\n",
    "\n",
    "    # 計算縮放係數 Scaling Factor\n",
    "    scale = 7 / abs_max_val\n",
    "\n",
    "    # 將 FP16 權重轉換為 INT4\n",
    "    weights = fp16_weights * scale\n",
    "    int4_weights = np.round(weights).astype(np.int8)\n",
    "\n",
    "    # 將數據限制在 INT4 範圍內 [-8, 7]\n",
    "    int4_weights = np.clip(int4_weights, -8, 7)\n",
    "\n",
    "    return int4_weights, scale\n",
    "\n",
    "# Input\n",
    "#     int4_weights   -   INT4 權重\n",
    "#     scale          -   縮放係數\n",
    "# Output\n",
    "#     fp16_weights   -   FP16 權重\n",
    "def dequantize_int4_to_fp16(int4_weights, scale):\n",
    "    # 將 INT4 權重轉換回 FP16\n",
    "    return int4_weights.astype(np.float16) / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d200729",
   "metadata": {},
   "source": [
    "轉換並觀察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e3c4847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original FP16 Weights: [ 1.    -0.5    0.25  -0.125]\n",
      "Int8 Weights: [ 7 -4  2 -1]\n",
      "Quantization Constant: 7.0\n",
      "Reconstructed FP16 Weights: [ 1.     -0.5713  0.2856 -0.1428]\n",
      "Original Output: 0.875\n",
      "Quantized Output: 0.857177734375\n",
      "Output Loss: 0.017822265625\n"
     ]
    }
   ],
   "source": [
    "# 假設我們有一組 FP16 權重\n",
    "w_fp16 = np.array([1.0, -0.5, 0.25, -0.125], dtype=np.float16)\n",
    "print(f\"Original FP16 Weights: {w_fp16}\")\n",
    "\n",
    "# 量化 FP16 權重到 INT4\n",
    "w_int4, sf = quantize_fp16_to_int4(w_fp16)\n",
    "print(f\"Int8 Weights: {w_int4}\")\n",
    "print(f\"Quantization Constant: {sf}\")\n",
    "\n",
    "# 將 INT4 權重反量化回 FP16\n",
    "rw_fp16 = dequantize_int4_to_fp16(w_int4, sf)\n",
    "print(f\"Reconstructed FP16 Weights: {rw_fp16}\")\n",
    "\n",
    "# 觀察輸出差異\n",
    "x = np.array([1.0, 0.25, -0.5, -1.0])\n",
    "y = np.matmul(x, w_fp16)\n",
    "qy = np.matmul(x, rw_fp16)\n",
    "loss = y - qy\n",
    "\n",
    "print(f\"Original Output: {y}\")\n",
    "print(f\"Quantized Output: {qy}\")\n",
    "print(f\"Output Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743c378",
   "metadata": {},
   "source": [
    "### 實際運算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b97f584",
   "metadata": {},
   "source": [
    "#### 產生隨機樣本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a5265c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化隨機數生成器的種子，以確保結果可重現\n",
    "np.random.seed(2135)\n",
    "\n",
    "# 設定輸入樣本數量、隱藏層大小與輸出類別數量 ------------------------\n",
    "# 輸入樣本數量\n",
    "# 有 12 筆樣本同時輸入（mini-batch size）\n",
    "inn_size = 12\n",
    "\n",
    "# 隱藏層大小\n",
    "# 每筆資料經過隱藏層後會轉換為 512 維向量\n",
    "hid_size = 512\n",
    "\n",
    "# 輸出類別數量（輸出向量長度）\n",
    "# 最終要分類為 4096 個類別（大型分類問題）\n",
    "out_size = 4096\n",
    "\n",
    "\n",
    "# 產生模型輸入、隱藏層權重與分類器權重 -----------------------------\n",
    "# 模型輸入\n",
    "# 輸入資料，共 12 筆樣本，每筆是 512 維（shape = 12×512）\n",
    "x = np.random.randn(inn_size, hid_size).astype(np.float16)\n",
    "\n",
    "# 隱藏層權重\n",
    "# 模擬隱藏層的權重，512×512（通常也會加 bias，但這裡省略）\n",
    "w_fp16 = np.random.randn(hid_size, hid_size).astype(np.float16)\n",
    "\n",
    "# 分類器權重\n",
    "# 模擬分類器（第二層全連接層）的權重，512×4096（輸出為每個類別的打分）\n",
    "# 使用 .astype(np.float16) 是為了模擬低精度運算，常見於 edge/AI 加速器部署\n",
    "clf = np.random.randn(hid_size, out_size).astype(np.float16)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 計算隱藏層輸出\n",
    "# 每筆輸入樣本經過 512 個隱藏神經元轉換後，輸出 shape 是 (12, 512)。\n",
    "# 通常這裡會加一個啟用函數（如 ReLU），但本例省略。\n",
    "hid = np.matmul(x, w_fp16)\n",
    "\n",
    "# 計算分類器輸出\n",
    "# out 的 shape 是 (12, 4096)，表示每筆樣本都有對 4096 類別的分數預測（logits）。\n",
    "out = np.matmul(hid, clf)   \n",
    "\n",
    "# 實際類別預測\n",
    "# 這行是對每筆樣本找出最大分數的類別編號（從 0 到 4095）：\n",
    "# np.argmax(out, -1) 會回傳 shape 為 (12,) 的向量，每個值是該筆樣本預測的類別。\n",
    "# 即完成分類任務的推論輸出。\n",
    "y = np.argmax(out, -1)      \n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 輸入 x (12×512)\n",
    "#     ↓（第一層）權重乘法：x @ w_fp16\n",
    "# 隱藏層輸出 hid (12×512)\n",
    "#     ↓（第二層）權重乘法：hid @ clf\n",
    "# 分類器輸出 out (12×4096)\n",
    "#     ↓\n",
    "# 使用 argmax 得到類別預測 y (12,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f43c546",
   "metadata": {},
   "source": [
    "#### FP16 量化成 INT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d385575c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP16 Prediction: [3956  874  201  109  843   46 1419 1058  865 2894 2059 1386]\n",
      "INT8 Prediction: [3956  874  201  109  843   46 1419 1058 1495 2894 2059 1386]\n",
      "INT8 Error: 1, Results: [ True  True  True  True  True  True  True  True False  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# 進行 INT8 量化並再次計算一次\n",
    "w_int8, sf = quantize_fp16_to_int8(w_fp16)\n",
    "rw_fp16 = dequantize_int8_to_fp16(w_int8, sf)\n",
    "hid = np.matmul(x, rw_fp16)\n",
    "out = np.matmul(hid, clf)\n",
    "y_int8 = np.argmax(out, -1)\n",
    "\n",
    "# 比較 INT8 量化的預測結果與原始輸出的差異\n",
    "errors_int8 = np.sum(np.not_equal(y, y_int8))\n",
    "\n",
    "print(f\"FP16 Prediction: {y}\")\n",
    "print(f\"INT8 Prediction: {y_int8}\")\n",
    "print(f\"INT8 Error: {errors_int8}, Results: {y == y_int8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda9df52",
   "metadata": {},
   "source": [
    "#### FP16 量化成 INT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1f63dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP16 Prediction: [3956  874  201  109  843   46 1419 1058  865 2894 2059 1386]\n",
      "INT4 Prediction: [3956 3782  242 1582  514 1716 2584 1058  865 2436 2059 1386]\n",
      "INT4 Error: 7, Results: [ True False False False False False False  True  True False  True  True]\n"
     ]
    }
   ],
   "source": [
    "# 進行 INT4 量化並再次計算一次\n",
    "w_int4, sf = quantize_fp16_to_int4(w_fp16)\n",
    "rw_fp16 = dequantize_int4_to_fp16(w_int4, sf)\n",
    "hid = np.matmul(x, rw_fp16)\n",
    "out = np.matmul(hid, clf)\n",
    "y_int4 = np.argmax(out, -1)\n",
    "\n",
    "# 比較 INT4 量化的預測結果與原始輸出的差異\n",
    "errors_int4 = np.sum(np.not_equal(y, y_int4))\n",
    "\n",
    "print(f\"FP16 Prediction: {y}\")\n",
    "print(f\"INT4 Prediction: {y_int4}\")\n",
    "print(f\"INT4 Error: {errors_int4}, Results: {y == y_int4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc09712",
   "metadata": {},
   "source": [
    "實驗結果\n",
    "* INT8 測試 12 個樣本只錯了 1 個\n",
    "* 但 INT4 錯了 7 個，誤差很大！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
