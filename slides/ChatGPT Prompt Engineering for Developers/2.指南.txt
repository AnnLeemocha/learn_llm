這段影片中，Isa 將會介紹一些撰寫提示（prompt）的指導方針，幫助你獲得你想要的結果。她特別會說明兩個關鍵原則，教你如何有效地進行提示工程（prompt engineering）。稍後她會展示 Jupyter Notebook 的範例，我也鼓勵你隨時暫停影片，自己執行這些程式碼，這樣你就可以看到輸出結果長什麼樣子，甚至可以變更提示內容、嘗試不同的變化，進而累積使用提示的實際經驗，了解輸入與輸出的關係。

接下來，我會概述一些在使用語言模型（例如 ChatGPT）時非常實用的原則與技巧。我會先從高層次的角度說明，然後再透過範例實際應用這些技巧，這些技巧也會貫穿整門課程。

### 原則一：撰寫清晰明確的指示  
第一個原則是撰寫**清楚且具體的指示**；第二個原則則是**給模型思考的時間**。  

開始之前，我們需要進行一點設定。在這門課程中，我們會使用 OpenAI 的 Python 函式庫來存取 OpenAI API。

如果你還沒安裝這個 Python 函式庫，可以用以下指令安裝：  
```bash
pip install openai
```
我自己已經安裝過這個套件了，所以我不會再執行這個指令。接下來，你可以匯入 `openai` 並設定你的 API 金鑰（這是一個秘密金鑰）。你可以從 OpenAI 的網站取得你的 API 金鑰，然後用以下方式設置：  

```python
openai.api_key = "你的API金鑰"
```

你也可以選擇把它設為環境變數。

不過在這門課裡，你其實不需要自己設定這些東西，因為我們已經在環境中設好 API 金鑰了，所以你可以直接執行程式碼，不用擔心運作原理。接下來，我們會使用 OpenAI 的 chatGPT 模型，也就是 GPT-3.5 Turbo，並透過「聊天補全」(chat completions) 這個 API 端點。詳細的輸入格式和參數，我們會在之後的影片深入探討。現在，我們先定義一個輔助函數 `getCompletion`，它會接收提示語，並回傳相應的輸出。

---

現在讓我們深入第一個原則：撰寫清晰明確的指示。

你應該盡可能清楚地描述你希望模型完成什麼任務。這樣可以引導模型產生符合預期的結果，並降低得到無關或錯誤回應的機率。

要注意，「清楚的提示」並不等於「簡短的提示」——很多時候，**較長的提示**反而能提供更多上下文資訊，讓模型能更精確地完成任務。

#### 技巧一：使用**分隔符號**標示輸入的不同部分  
舉個例子，我們有一段段落，我們的任務是將這段內容總結成一句話。在提示語中，我們寫：

```
Summarize the text delimited by triple backticks into a single sentence.
```

然後我們用三個反引號 ```（triple backticks）將文本括起來。執行後，模型輸出了一個句子。這樣的分隔讓模型明確知道該處理哪段文字。你也可以用其他分隔符號，像是引號、XML 標籤、段落標題等等。

**使用分隔符號的另一個好處**是可以減少提示注入（prompt injection）的風險。提示注入是指使用者輸入具有誤導性的內容，讓模型偏離原本的指示。如果我們明確告訴模型「只處理這段被分隔的文字」，就比較不容易被誘導。

#### 技巧二：要求**結構化輸出**  
為了讓模型輸出的結果更容易分析，你可以要求它用像 JSON 或 HTML 的格式呈現。

例如，請模型生成三本虛構書籍的清單，包括書名、作者與類型，並以 JSON 格式呈現。這樣的輸出能輕易被 Python 轉成字典或清單來處理。

#### 技巧三：請模型先**檢查條件**  
如果任務需要某些前提成立才能執行，可以先請模型檢查這些條件是否滿足，再決定是否繼續。例如，我們給模型一段描述泡茶過程的文字，並請它只在文本中有「步驟」時，才將其轉換為清單格式；否則就回傳「No steps provided」。

#### 技巧四：使用**few-shot prompting（少量範例提示）**  
這是指在真正的任務提示前，先給模型一些成功範例。例如，先給模型一段小孩與爺爺的對話，爺爺用比喻方式教導耐心；接著請模型用類似風格解釋「韌性」。這樣可以幫助模型掌握語氣與風格。

---

### 原則二：給模型**思考的時間**

如果模型在面對複雜問題時，太快得出錯誤結論，那就應該讓它「一步步推理」後再作答。這個概念就像人類一樣——面對複雜數學問題，如果沒有時間思考，也容易出錯。

#### 技巧一：**明確列出任務步驟**  
舉例來說，我們請模型：

1. 總結 Jack 和 Jill 的故事段落；
2. 翻譯這個總結成法文；
3. 列出法文總結中出現的名字；
4. 以 JSON 格式輸出總結與名字數量。

這樣分步描述能讓模型更有條理地完成任務，也能避免格式混亂。

#### 技巧二：**請模型自己先解題**  
如果你要模型判斷學生的解答是否正確，建議先讓它「自己先解一遍」問題，再跟學生的答案比對。  

例如，我們提供一個數學問題與學生的解答。模型一開始只「讀」了學生的答案，就判斷正確，但其實那答案有錯。我們可以修改提示，明確要求模型自己先解題，再比對學生的做法，這樣模型就會發現錯誤並指出來。

---

### 模型的限制

雖然語言模型在訓練期間接觸過大量知識，但它並沒有完美記憶所有資訊，而且也不清楚自己的知識邊界。

這代表它可能會試圖回答一些其實不知道答案的問題，甚至編造看起來很合理但實際上是假的內容——這種現象稱為**幻覺（hallucination）**。

我們來看一個範例：如果請模型介紹一個不存在的牙刷產品（例如某個品牌的「AeroGlide Ultra Slim Smart Toothbrush」），它可能會給出一段非常真實聽起來像真的產品描述，但其實這是它「憑空捏造」的。

為了減少這種情況，你可以要求模型先找出來自原始文件的相關引用，再根據這些引用回答問題。這樣做可以追溯答案來源，進而降低幻覺風險。

---

以上就是提示撰寫的基本原則與技巧！接下來的影片會介紹**提示的迭代開發流程（iterative prompt development process）**，敬請期待。