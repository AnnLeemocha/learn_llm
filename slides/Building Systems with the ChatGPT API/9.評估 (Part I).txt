在前幾個影片中，Isa 展示了如何使用 LLM 建立一個應用程式，從評估輸入、處理輸入到最後的輸出檢查，然後再將輸出顯示給使用者。

當您建立了這樣一個系統後，您如何知道它的運作情況呢？甚至當您將其部署並讓用戶使用時，您如何追蹤它的表現，發現任何不足之處，並繼續提升系統回答的質量？

在這個影片中，我想與您分享一些評估 LLM 輸出的最佳實踐，並特別與您分享建立這些系統時的感受。

在這個影片中，我所談到的與您在傳統機器學習監督學習應用中可能見過的區別之一是，由於您可以非常快速地建立這樣的應用，評估它的方法往往不會從測試集開始。相反，您通常會逐漸建立一組測試範例。

讓我來解釋一下我的意思。

您可能記得在第二個影片中提到的這個圖示，說明基於提示的開發如何將模型開發的核心部分從可能需要幾個月縮短為幾分鐘、幾小時，或最多幾天的時間。

在傳統的監督學習方法中，如果您需要收集 10,000 個標註範例，那麼收集另外 1,000 個測試範例的額外成本不會太高。因此，在傳統的監督學習設定中，收集訓練集、開發集或保留交叉驗證集和測試集並在這個開發過程中隨時使用它們並不罕見。

但如果您能在幾分鐘內指定一個提示，並在幾小時內讓它運作，那麼如果您需要停下來收集 1,000 個測試範例，這會是一件非常麻煩的事情，因為您無法在沒有任何訓練範例的情況下讓它運作。

因此，在使用 LLM 建立應用程式時，這通常是它的運作方式。首先，您會在少數幾個範例上進行提示微調，可能是一到三到五個範例，並嘗試找到能夠運作的提示。

然後，當您的系統進行額外測試時，您偶爾會遇到一些棘手的範例，提示無法處理這些範例，或者算法無法處理它們。

在這種情況下，您可以將這些額外的 1、2、3 或 5 個範例加入到您測試的範例集中，逐步將更多棘手的範例加入。

最終，您會有足夠多的這些範例，並且它們會逐漸使您的開發集變得更大，以至於每次修改提示時手動運行每個範例變得不太方便。

這時，您會開始開發一些度量指標來衡量在這些小範例集上的表現，例如可能是平均準確度。而這個過程的一個有趣方面是，如果您在任何時候決定，您的系統運作得足夠好，您可以就此停止，不再繼續進行下一步。

事實上，許多已經部署的應用程式就是在第一步或第二步就停下來了，並且運行得相當順利。

現在，如果您正在評估模型的手工開發集還無法讓您對系統的表現產生足夠的信心，那麼您可能會進入下一步，收集隨機抽樣的一組範例來微調模型。

這將繼續作為開發集或保留交叉驗證集，因為繼續微調您的提示對此是非常常見的。只有當您需要更高精度的系統表現估算時，您才可能收集並使用一組保留的測試集，並且在微調模型時完全不會查看這些測試集。因此，第四步在某些情況下會變得更加重要，例如，如果您的系統有91%的準確率，而您希望將準確率提升到92%或93%，那麼您確實需要更大的一組範例來衡量91%與93%之間的差異。

只有當您真正需要一個無偏、公正的估算來評估系統表現時，您才需要超越開發集，收集一個保留的測試集。一個重要的警告是，我看到很多大型語言模型的應用中，如果模型給出的答案不完全正確，並不會帶來實質性的危害。

但顯然，對於任何高風險的應用，如果存在偏見或不恰當的輸出可能對某些人造成傷害，那麼負責收集測試集，嚴格評估系統的表現以確保它在使用之前是正確的，這變得更加重要。但例如，如果您僅是為自己閱讀而使用它來摘要文章，並且沒有其他人使用，那麼造成傷害的風險可能較小，您可以在過程中較早停止，而無需進行第四和第五步，並收集更大的數據集來評估您的算法。

那麼在這個例子中，讓我從通常的輔助函數開始。使用 utils 函數來獲取產品和類別的列表。

在電腦與筆記型電腦類別中，這裡列出了電腦與筆記型電腦，在智能手機與配件類別中，這裡列出了智能手機與配件，其他類別也如此。

現在，假設我們要處理的任務是，根據用戶的輸入，比如「如果我預算有限，我可以買什麼電視？」來檢索相關的類別和產品，以便我們能夠回答用戶的問題。

這裡是一個提示，您可以隨意暫停影片並詳細閱讀。這個提示規定了一組指令，並實際上給語言模型提供了一個良好的輸出範例。這有時被稱為少量範例提示，或技術上稱為單一範例提示，因為我們實際上使用了用戶訊息和系統訊息，給它一個良好的輸出範例。如果有人說「我想要最貴的電腦。」那麼我們就返回所有電腦，因為我們沒有定價信息。現在，我們來用這個提示處理客戶訊息「如果我預算有限，我可以買什麼電視？」

所以我們傳遞給它的包含提示、客戶訊息和產品與類別，這是我們使用 utils 函數在上面檢索到的資料。

這裡列出了與這個查詢相關的信息，屬於「電視與家庭影院系統」類別。

這是看起來相關的電視和家庭影院系統的列表。

要查看提示的效果，您可以在第二個提示上進行評估。

客戶說：「我需要一個智能手機充電器。」

看起來它正確地檢索到這些資料。

類別：智能手機，配件，並列出了相關的產品。

再來一個例子。

「你們有什麼電腦？」

希望它能檢索到一個電腦的列表。

所以，這裡我有三個提示，如果您是第一次開發這個提示，那麼有一兩個範例是很合理的，並且會不斷微調提示，直到它給出適當的輸出，直到提示能夠為您的所有提示（在這個例子中的三個提示）檢索到相關的產品和類別。如果提示錯過了一些產品，那麼我們可能會回去編輯提示幾次，直到它在所有三個提示中都能正確檢索到。當您把系統調整到這個階段後，您可能會開始運行系統進行測試。也許可以發送給內部測試用戶，或者自己嘗試運行一段時間，看看會發生什麼。

有時，您會遇到一個提示系統無法處理的情況。這裡有一個提示範例：「告訴我關於 smartx pro 電話和 fotosnap 相機的信息。還有，你們有什麼電視？」

當我在這個提示上運行時，它看起來輸出了正確的數據，但它也輸出了一些多餘的文本，這些額外的雜訊。這使得將其解析為 Python 字典列表變得更加困難。我們不喜歡它輸出這些額外的雜訊。因此，當您遇到一個系統無法處理的範例時，通常的做法是記下這個範例是有點棘手的，所以我們將它添加到我們要系統地測試的範例集中。

如果您繼續運行系統一段時間，也許它會在這些範例上工作。我們確實對三個範例進行了微調，所以它可能會在許多範例上有效，但只是碰巧您可能會遇到另一個例子，系統會出錯。

所以這個客戶訊息也會讓系統在輸出結尾處產生一堆我們不想要的雜訊文本。

它試圖幫忙給出所有這些額外的文本，

但我們其實不需要這些。

到這個時候，您可能已經在數百個範例上運行過這個提示，可能還有測試用戶，但您現在會將那些表現不佳的棘手範例拿出來，並擁有這一組範例，從 0 到 4 共五個範例，您可以用這些範例來進一步微調提示。

在這兩個範例中，LLM 輸出了許多額外的垃圾文字，我們並不需要這些。經過一點試錯，您可能會決定修改提示，讓它變成這樣：

這是一個新的提示，稱為 v2 版本。

但我們在這裡所做的是，我們在提示中加入了「不要輸出任何不在 JSON 格式中的額外文本」，強調請不要輸出這些額外的文本。

並且使用了第二個範例，這是使用用戶和助手訊息的少量範例提示，當用戶要求最便宜的電腦時。

在這兩個少量範例中，我們向系統展示了一個只返回 JSON 輸出的回應。因此，這是我們剛剛加入到提示中的內容：「不要輸出任何不在 JSON 格式中的額外文本」，並使用了「few_shot_user_1」、「few_shot_assistant_1」以及「few_shot_user_2」、「few_shot_assistant_2」來提供這兩個少量範例提示。

讓我按 Shift-Enter 來找到這個提示。然後您需要回去手動重新運行這個提示，對所有五個用戶輸入範例進行測試，包括之前輸出有錯誤的範例，您會發現現在它會給出正確的輸出。如果您回去並重新運行這個新的提示，也就是提示版本 v2，對於那個輸出有錯誤（附加垃圾文字）的客戶訊息範例，它將產生更好的輸出。

我這裡不會實際操作，但我鼓勵您暫停影片，並自己在客戶訊息 4 上運行這個提示 v2，看看它是否也能產生正確的輸出。

希望它會，應該會。當然，當您修改提示時，進行一些回歸測試也很有用，以確保在修正提示 3 和 4 中的錯誤輸出時，不會破壞提示 0 的輸出。

現在，您可以大致猜到，如果我需要將 5 個提示（例如客戶訊息 0、1、2、3 和 4）複製並粘貼到我的 Jupyter Notebook 中運行，然後手動檢查它們，看看它們是否輸出了正確的類別和產品。這樣做是可以的。我可以查看這個結果，並說「是的，類別是電視和家庭影院系統，產品？是的，看起來你把所有的都列出來了。」

但實際上，這樣手動檢查其實有點痛苦，要手動檢查或查看這些輸出，確保它們完全正確。因此，當您微調的開發集不再只是少數幾個範例時，開始自動化測試過程就變得有用。

這裡有一組 10 個範例，我在其中指定了 10 條客戶訊息。這是客戶訊息「如果我預算有限，我可以買什麼電視？」以及理想的答案。可以把這看作是測試集中的正確答案，或者更準確地說，我應該說是開發集，因為我們實際上是在對它進行微調。因此，我們在這裡收集了 10 個範例，編號從 0 到 9，其中最後一個是如果用戶說「我想要熱水浴缸時間機」，對此我們沒有相關的產品，真的很抱歉，所以理想答案是空集。

現在，如果您想要自動評估提示在這 10 個範例上的表現，這裡有一個函數來執行此操作。這是一個相對長的函數，您可以隨意暫停影片並閱讀它。如果願意，我會簡單演示它的實際操作。

讓我先打印出客戶訊息，對於客戶訊息 0。

所以客戶訊息是「如果我預算有限，我可以買什麼電視？」

我們還會打印出理想答案。理想答案是這裡列出的所有電視，這是我們希望提示檢索到的。

現在，讓我調用提示。這是對於這個客戶訊息，使用提示 V2，並帶入用戶的產品和類別信息。讓我們打印出來，然後我們會調用 eval 函數來看看回應與理想答案的匹配情況。

在這個案例中，它確實輸出了我們想要的類別，並且輸出了完整的產品列表。

因此，它給出了 1.0 的分數。

再給您展示一個例子，事實上我知道它在範例 7 上出錯了。

所以，如果我把它從 0 改為 7 並運行，這是它得到的結果。哦，讓我把這個也更新為 7。

所以在這個客戶訊息下，這是理想的答案，它應該輸出的是「遊戲主機和配件」類別。也就是遊戲主機和配件的列表。

但是這裡的回應只有三個輸出，實際上應該有 1、2、3、4、5 個輸出。因此，它漏掉了一些產品。

所以，如果我現在正在微調這個提示，我會使用折疊（fold）來遍歷所有 10 個開發集範例，反覆提取客戶訊息、獲取理想答案、調用模型來獲得回應，然後評估，最後將結果累積並計算平均值。讓我運行這個。

這將需要一段時間來運行，但當它運行完成後，這是結果。我們運行了 10 個範例，似乎範例 7 出錯了。因此，10 個範例中的正確比例為 90%。

所以，如果您要微調提示，您可以重新運行此操作，看看正確率是上升還是下降。

您剛剛在這個 Jupyter Notebook 中看到的是步驟 1、2 和 3，這已經提供了一個相當好的開發集，這 10 個範例可以用來微調並驗證提示是否有效。

如果您需要更高的嚴謹性，那麼您現在擁有了軟體來收集一組隨機抽樣的 100 個範例及其理想輸出，甚至可以進一步嚴格地使用保留測試集來進行微調，而您在微調提示時甚至不需要查看該測試集。但對於很多應用來說，在步驟 3 停止就可以了，當然，也有一些應用可以像您剛才看到的那樣，在 Jupyter Notebook 中操作，快速得到一個相當有效的系統。

再次提醒，如果您在做的是一個安全關鍵的應用，或是有非平凡傷害風險的應用，當然，負責任的做法是實際上收集一個更大的測試集，來在使用前驗證系統的性能。

就這樣。我發現使用提示來構建應用的工作流程與使用監督學習來構建應用的工作流程非常不同，並且迭代的速度感覺要快得多。如果您以前沒做過這個，您可能會驚訝於僅依賴少數精心挑選的棘手範例來構建的評估方法的有效性。您可能會認為用 10 個範例並不具備統計有效性，但當您實際使用這個程序時，您會驚訝於將少數幾個棘手範例加入開發集對幫助您和您的團隊達成有效的提示和有效系統的幫助。

在這個影片中，輸出是可以定量評估的，也就是有理想的輸出，您可以確定它是否給出了這個理想輸出。所以下一個影片，我們將看看如何在回答較為模糊的情境下評估輸出。