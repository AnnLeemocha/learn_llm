在這段影片中，我想和你分享大型語言模型（LLM, Large Language Models）是如何運作的概覽。我們會探討它們是如何被訓練的，以及像是「分詞器（tokenizer）」等細節，並了解這些細節如何影響你在提示（prompt）LLM時的輸出結果。

我們也會看看LLM的對話格式，也就是如何同時指定系統訊息與使用者訊息的方式，並理解你可以如何善用這個功能。我們一起來看看吧！

首先，大型語言模型是怎麼運作的？

你可能已經熟悉文字生成的過程，比如你給一個提示「我喜歡吃」，然後讓LLM補齊這段文字，它可能會回覆「奶油起司貝果」、「我媽媽的肉捲」或是「跟朋友一起出去吃飯」。

那麼，這個模型是怎麼學會這些的呢？

訓練LLM的主要技術，其實是「監督式學習（supervised learning）」。在監督式學習中，電腦會根據標記好的訓練數據，學會從輸入（X）對應到輸出（Y）的映射。

例如，如果你用監督式學習來訓練模型判斷餐廳評論的情緒，你可能會蒐集像這樣的訓練數據：

「煙燻牛肉三明治很好吃！」 → 標記為正面情緒

「服務很慢，食物普普通通。」 → 標記為負面情緒

「伯爵茶真是太棒了。」 → 標記為正面情緒

（順帶一提，我跟Isa都是在英國出生的，所以我們都很喜歡伯爵茶。）

監督式學習的過程，通常就是取得標記過的資料，然後用來訓練一個AI模型。

訓練完成後，你就可以用這個模型來處理新資料，例如：

「這是我吃過最棒的披薩。」

模型應該會判斷這是正面的情緒。

其實，監督式學習是訓練LLM的核心基礎之一。具體來說，LLM會透過不斷地學習「預測下一個詞」來進行訓練。

假設你的訓練資料中有這樣一句話：

「我最喜歡的食物是奶油起司燻鮭魚貝果。」

這句話會被轉換為一系列訓練樣本，例如：

給出「我最喜歡的食物是」→ 預測下一個詞「貝果」

給出「我最喜歡的食物是貝果」→ 預測下一個詞「加」

以此類推...

如果你擁有數千億個詞的訓練資料，就可以創造一個非常龐大的訓練集，讓語言模型學會預測下一個詞是什麼。

目前有兩大類型的LLM：

基礎LLM（Base LLM）

指令微調LLM（Instruction Tuned LLM），現在這種類型越來越常見。

基礎LLM是根據文字訓練資料，重複預測下一個詞。例如你輸入：

「從前從前，有一隻獨角獸……」

它可能會補完這個故事，描述這隻獨角獸住在魔法森林，和她的獨角獸朋友們一起生活。

但這類模型的缺點是，如果你問：

「法國的首都是哪裡？」

它可能只是列出一堆關於法國的問答題，如：

「法國最大城市是什麼？法國人口是多少？」等等。

而你真正想要的答案是：

「法國的首都是巴黎。」

這時就要用「指令微調LLM」，它會學著照指令行事，像這樣回應：

「法國的首都是巴黎。」

那麼，我們怎麼從一個基礎LLM變成指令微調的LLM呢？這正是像ChatGPT這樣模型的訓練過程。

首先，你會用數千億字甚至更多資料訓練一個Base LLM，這個過程可能要花好幾個月，還需要大型超級電腦系統。

接著，你會進行微調（fine-tuning），用一小批資料繼續訓練，這些資料包含了「指令 → 回應」的對應關係。你可能會請人撰寫大量這樣的例子，讓模型學習如何根據指令生成適當的回應。

為了進一步提升輸出品質，現在常用的方法是請人類對不同輸出結果打分，例如根據是否「有幫助、誠實、無害」來評估。

然後再根據這些人類評分，進一步微調模型，提升模型產生高評價回應的機率。這種技術稱為「從人類回饋中強化學習（RLHF, Reinforcement Learning from Human Feedback）」

雖然訓練Base LLM要好幾個月，但從Base模型進一步微調成Instruction Tuned模型，可能只要幾天，而且所需的資料量與計算資源也比較少。

接著，我們來看看實際如何使用LLM。我會匯入一些程式庫，載入我的OpenAI金鑰（API key），並示範如何呼叫API取得回應。

如果你還沒安裝OpenAI套件，可以執行 pip install openai。我這邊已經裝好了，就不再執行。

然後我執行以下程式碼：response = get_completion("法國的首都是哪裡？")

希望它會給我正確答案。

在剛剛對大型語言模型的描述中，我提到它是「逐字預測下一個詞」，但實際上，還有一個非常重要的技術細節：

當你請模型將單字 "lollipop" 的字母反過來排序時，這看起來像是個簡單任務，可能連四歲小孩都會做。但如果你問 ChatGPT，它卻常常給出錯亂的結果，並不是「P-O-P-I-L-L-O-L」這樣正確的反轉。

為什麼會這樣呢？

原因在於，LLM 並不是預測「下一個詞」，而是預測「下一個**token（標記）**」。

LLM 會將一段文字（例如 "Learning new things is fun!"）轉換為一連串的 token，而這些 token 是由常見的字母組合或詞語組成。

在像 "Learning new things is fun!" 這種句子中，每個詞都相對常見，所以每個 token 就對應一個詞或是一個詞+空格、標點符號等。

但如果你輸入像是 "Prompting as a powerful developer tool."，其中 "prompting" 雖然越來越常見，但它仍然不算高頻詞。LLM 的 tokenizer 會把這個詞切分成三個 token：`"prom"`, `"pt"`, 和 `"ing"`，因為這三個組合在其他詞中經常出現。

對於像 "lollipop" 這樣的詞，tokenizer 會將它切分成 `"I"`, `"oll"`, `"ipop"` 三個 token。

所以 ChatGPT 並不是看到「l」、「o」、「l」... 這些字母，而是看到這些較大的片段（tokens），這使得它無法正確地反轉每個字母。

那怎麼辦呢？

這裡有個小技巧。如果你在字母之間加入破折號（或空格也行），像這樣 "L-O-L-L-I-P-O-P"，然後再請它反轉，ChatGPT 通常就能正確地輸出反轉結果，因為這樣每個字母就會成為一個獨立的 token，讓模型更容易「看見」並處理每個字母。

這個技巧在玩文字遊戲（例如 Scrabble、猜單字）時特別有用。

順帶一提，在英文中，一個 token 平均大約等於 4 個字母，或大約 0.75 個單字。

不同的 LLM 模型會有不同的「token 限制」，也就是輸入（context）和輸出（completion）加總起來的最大 token 數。例如，GPT-3.5 Turbo 模型的限制大約是 4,000 個 token。

所以，如果你輸入太長，超過這個限制，模型可能會報錯或無法正確執行。

接下來，我要分享另一種強大的使用 LLM API 的方式：**使用多段對話格式（Messages Format）**，這種格式讓你可以分別指定 system、user 和 assistant 的訊息。

我們來看個範例再解釋它的原理：

這是一個新的輔助函數叫 `get_completion_from_messages`，當你呼叫這個函數時，你會給它一個「訊息清單」。

範例如下：

```python
messages = [
    {"role": "system", "content": "你是一位用 Dr. Seuss 風格說話的助理。"},
    {"role": "user", "content": "請幫我寫一首關於快樂紅蘿蔔的短詩。"}
]
```

執行後，ChatGPT 會根據這些訊息回應。這時我設定 `temperature=1`（創意度較高），模型可能會生成像：

「哦，多麼歡樂的紅蘿蔔，在陽光下快樂跳躍！」

還挺押韻的，寫得不錯！👏

這裡的重點是：

- `system` 訊息：設定整體語氣或風格，例如 Dr. Seuss 的說話風格。
- `user` 訊息：指定具體的請求，例如「幫我寫一首詩」。

如果你想進行多輪對話，也可以加入 `assistant` 訊息，把過去模型的回應放進去，讓模型記得它之前說過什麼。

你也可以這樣組合應用：

如果你想讓它只回一句話，你可以在 system 訊息中這樣寫：

```python
{"role": "system", "content": "你所有的回覆都必須只有一句話。"}
```

或者結合多種要求：

```python
{"role": "system", "content": "你是一位用 Dr. Seuss 風格說話的助理，你所有的回覆都必須只有一句話。"}
```

執行後，它可能會生成：

「他總是微笑，永遠不會嚇人。」

是不是很可愛？😊

---

還沒完！如果你想知道呼叫 API 時用了多少 token，這裡有個進階的輔助函數，它會回傳：

- 提示（prompt）用了多少 token
- 回覆（completion）用了多少 token
- 總共用了多少 token

例如，它可能會回報：

```
提示 token：37  
回覆 token：55  
總共：92 token
```

在實際應用中，大多時候我不會太在意 token 數量，但如果你懷疑使用者輸入過長，可能超過限制，這時就很有必要檢查一下 token 數，並做出截斷處理。

---

接著我想再分享一個小技巧：**安全地使用 API 金鑰（API Key）**。

許多開發者會直接把金鑰寫在程式碼中，例如：

```python
openai.api_key = "your_api_key"
```

這樣做**不安全**，因為你很容易不小心把 notebook 傳給別人，或把它上傳到 GitHub，進而洩漏你的金鑰。

正確的做法是使用 `.env` 檔案搭配 `dotenv` 函式庫：

```python
from dotenv import load_dotenv, find_dotenv
load_dotenv(find_dotenv())
openai.api_key = os.getenv("OPENAI_API_KEY")
```

這樣你就可以將金鑰儲存在 `.env` 文件中，而不是寫在程式碼裡，這樣比較安全。而且這種方法也適用於多種其他 API 金鑰管理方式。

---

最後，我想說明一點：**提示工程（prompting）正在顛覆整個 AI 應用的開發流程。**

在傳統的監督式機器學習流程中，像前面說的餐廳評論分類系統：

1. 收集標記資料 → 幾百筆，可能要幾週
2. 訓練模型 → 數天到數週
3. 評估 → 數天
4. 上雲部署 → 整體可能要幾個月

但現在，如果你使用提示方式（prompt-based ML），當你要開發文字相關的應用時：

- 你只需幾分鐘或幾小時就能寫好 prompt
- 幾小時內就可以透過 API 開始測試
- 幾小時內就可以部署並實際使用

以前要花半年或一年的東西，現在用 prompt 可能幾個小時就完成了。

不過，要注意的是，這主要適用於「非結構化資料」的應用，如文字與越來越多的圖像應用（視覺AI目前還在發展中），但對於「結構化資料」應用（例如 Excel 表格的數值分析）就沒那麼有效了。

儘管如此，這樣快速開發 AI 模組的能力，已經徹底改變了我們開發整個系統的方式。儘管整體系統開發仍需數天或數週，但這部分可以大幅加快速度。

---

接下來的影片中，Isa 將示範如何使用這些元件來評估客服助理的輸入內容。我們會在這堂課中持續開發一個完整的案例：為一間線上零售商建立一個客服助理。
