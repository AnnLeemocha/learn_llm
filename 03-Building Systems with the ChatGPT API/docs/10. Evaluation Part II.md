# Evaluation Part II 評估第二部分
(續)
前面的範例，輸出結果是可以定量評估的，也就是有理想的輸出，但在回答較為模糊的情境下，要如何評估輸出？
* 明確正確答案情境：
    * 使用函數直接比較輸出與標準答案是否一致。
    * 前例
* 開放式文字輸出情境：
    * 正確答案本身具有多樣性，「無唯一正確答案」，需採用更主觀與語義導向的評估方法。
    * 例如，生成文字內容

---

## 兩種評估設計模式
1. 使用「評分規則（Rubric）」讓 LLM 自評輸出品質
   * Rubric 是一組明確的「評分準則」，用來從多角度檢查回答品質，使用模型協助判斷輸出是否合格。
   * 說明範例的評估流程：
        1. 準備資料：
            * 客戶輸入（Customer message）
            * 系統提供的上下文資料（商品與分類資訊）
            * 模型的回答（Assistant answer）
        2. 撰寫 Rubric： 引導模型自評輸出內容
            * 回答是否只根據上下文？
            * 是否添加了上下文以外的資訊？
            * 是否與上下文內容矛盾？
            * 是否有完整回答問題？
        3. 設計 Prompt：
            * 請 LLM 擔任一名評估助理，根據 rubric 分析 LLM 回覆。
            * 終回答輸出「是 / 否」、「合理 / 不合理」等簡單結論與說明。
    * 就算沒有專家提供的理想答案，只要你能撰寫一份評分標準（rubric），就能用一個 LLM 來評估另一個 LLM 的輸出。
2. 有理想答案時，使用 LLM 比對產出與「專家範例」的相似度
    * 比較「 LLM 的回應」與人類專家撰寫的「理想回答」之間的語意與內容一致性。
    * 說明範例的評估流程：
        1. 準備資料：
            * 客戶輸入（Customer message）
            * 專家理想回答（Expert ideal answer）
            * 模型的回答（Assistant answer）
        2. 比對兩個回答是否一致：
            * [BLEU 分數](https://en.wikipedia.org/wiki/BLEU):
              衡量一段文字與另一段文字的相似程度。
            * rubric：
              忽略風格、文法或標點差異，比較兩者在事實層面是否一致
        3. 分數等級（A ~ E，取自 OpenAI 評估框架）：
            * [OpenAI evals](https://github.com/openai/evals/blob/main/evals/registry/modelgraded/fact.yaml):
              這份 rubric 來自 OpenAI 的開源評估框架，其中包含了 OpenAI 開發者與開源社群貢獻的多種評估方法。
              (要求 LLM 根據比較結果，從 A 到 E 評分)
                | 分數等級 | 說明                                         |
                | -------- | -------------------------------------------- |
                | A        | 模型回答是理想答案的子集，且完全一致         |
                | B        | 模型回答是理想答案的超集，但完全一致（可能產生幻覺或捏造了額外的資訊） |
                | C        | 模型回答與理想答案一致，包含所有細節         |
                | D        | 有明顯衝突                                   |
                | E        | 回答與理想答案差異過大，不具參考價值         |
    * 如果你能提供專家撰寫的理想答案，那麼你可以讓 LLM 更好地判斷某個助理回答是否與該理想答案相似。

---

## 說明範例

### 透過端對端系統運行來回答用戶查詢
這些輔助函數為前例的範例。
```python
customer_msg = f"""
tell me about the smartx pro phone and the fotosnap camera, the dslr one.
Also, what TVs or TV related products do you have?"""

products_by_category = utils.get_products_from_query(customer_msg)

category_and_product_list = utils.read_string_to_list(products_by_category)

product_info = utils.get_mentioned_product_info(category_and_product_list)

assistant_answer = utils.answer_user_msg(user_msg=customer_msg, product_info=product_info)
```

### 1. 根據擷取的產品訊息，使用評分標準評估 LLM 對使用者的回答 (rubric)
準備資料: 
建立一個資料結構來儲存客戶訊息以及產品資訊。
```python
cust_prod_info = {
    'customer_msg': customer_msg,
    'context': product_info
}
```
撰寫 Rubric（範例準則），並設計 Prompt 來評估助理的回答。
```python
def eval_with_rubric(test_set, assistant_answer):

    cust_msg = test_set['customer_msg']
    context = test_set['context']
    completion = assistant_answer
    
    # 你是一位評估客服人員回答品質的助理，透過檢視客服人員產出回應所使用的上下文內容來進行評估。
    system_message = """\
    You are an assistant that evaluates how well the customer service agent \
    answers a user question by looking at the context that the customer service \
    agent is using to generate its response. 
    """

    # 提供資料: 客戶的請求、上下文（產品與分類資訊），以及 LLM 的輸出(前例產生的回應)。
    user_message = f"""\
You are evaluating a submitted answer to a question based on the context \
that the agent uses to answer the question.
Here is the data:
    [BEGIN DATA]
    ************
    [Question]: {cust_msg}
    ************
    [Context]: {context}
    ************
    [Submission]: {completion}
    ************
    [END DATA]

# Rubric: 比較提交的答案與上下文的事實內容是否一致。忽略文體、文法或標點的差異。
Compare the factual content of the submitted answer with the context. \
Ignore any differences in style, grammar, or punctuation.
Answer the following questions:
    - Is the Assistant response based only on the context provided? (Y or N)
    - Does the answer include information that is not provided in the context? (Y or N)
    - Is there any disagreement between the response and the context? (Y or N)
    - Count how many questions the user asked. (output a number)
    - For each question that the user asked, is there a corresponding answer to it?
      Question 1: (Y or N)
      Question 2: (Y or N)
      ...
      Question N: (Y or N)
    - Of the number of questions asked, how many of these questions were addressed by the answer? (output a number)
"""

    messages = [
        {'role': 'system', 'content': system_message},
        {'role': 'user', 'content': user_message}
    ]

    response = get_completion_from_messages(messages)
    return response
```
輸出評估結果
```python
evaluation_output = eval_with_rubric(cust_prod_info, assistant_answer)
print(evaluation_output)
```

### 2. 根據「理想」/「專家」（人工生成的）答案評估 LLM 對使用者的回答。
測試集: 客戶訊息、理想回應
```python
test_set_ideal = {
    'customer_msg': """\
tell me about the smartx pro phone and the fotosnap camera, the dslr one.
Also, what TVs or TV related products do you have?""",
    'ideal_answer':"""\
Of course!  The SmartX ProPhone is a powerful \
smartphone with advanced camera features. \
For instance, it has a 12MP dual camera. \
Other features include 5G wireless and 128GB storage. \
It also has a 6.1-inch display.  The price is $899.99.

The FotoSnap DSLR Camera is great for \
capturing stunning photos and videos. \
Some features include 1080p video, \
3-inch LCD, a 24.2MP sensor, \
and interchangeable lenses. \
The price is 599.99.

For TVs and TV related products, we offer 3 TVs \


All TVs offer HDR and Smart TV.

The CineView 4K TV has vibrant colors and smart features. \
Some of these features include a 55-inch display, \
'4K resolution. It's priced at 599.

The CineView 8K TV is a stunning 8K TV. \
Some features include a 65-inch display and \
8K resolution.  It's priced at 2999.99

The CineView OLED TV lets you experience vibrant colors. \
Some features include a 55-inch display and 4K resolution. \
It's priced at 1499.99.

We also offer 2 home theater products, both which include bluetooth.\
The SoundMax Home Theater is a powerful home theater system for \
an immmersive audio experience.
Its features include 5.1 channel, 1000W output, and wireless subwoofer.
It's priced at 399.99.

The SoundMax Soundbar is a sleek and powerful soundbar.
It's features include 2.1 channel, 300W output, and wireless subwoofer.
It's priced at 199.99

Are there any questions additional you may have about these products \
that you mentioned here?
Or may do you have other questions I can help you with?
    """
}
```

### 檢查LLM的回覆是否同意或不同意專家的答案
[BLEU 分數](https://en.wikipedia.org/wiki/BLEU)：評估兩段文字是否相似的另一種方法。

此評估提示來自 [OpenAI evals](https://github.com/openai/evals/blob/main/evals/registry/modelgraded/fact.yaml) 專案。
撰寫 Rubric（範例準則），並設計 Prompt 來評估助理的回答。
```python
def eval_vs_ideal(test_set, assistant_answer):

    cust_msg = test_set['customer_msg']
    ideal = test_set['ideal_answer']
    completion = assistant_answer
    
    # 你是個助手，透過比較客服人員的回答與理想（專家）回答來評估客服人員回答使用者問題的能力，輸出一個字母而不輸出其他內容。
    system_message = """\
    You are an assistant that evaluates how well the customer service agent \
    answers a user question by comparing the response to the ideal (expert) response
    Output a single letter and nothing else. 
    """

    # 提供資料: 客戶的請求、專家撰寫的理想答案，以及 LLM 的輸出(前例產生的回應)。
    user_message = f"""\
You are comparing a submitted answer to an expert answer on a given question. Here is the data:
    [BEGIN DATA]
    ************
    [Question]: {cust_msg}
    ************
    [Expert]: {ideal}
    ************
    [Submission]: {completion}
    ************
    [END DATA]

# Rubric: 比較提交的回答與專家回答的事實內容是否一致。忽略風格、文法或標點的差異。
Compare the factual content of the submitted answer with the expert answer. Ignore any differences in style, grammar, or punctuation.
    The submitted answer may either be a subset or superset of the expert answer, or it may conflict with it. Determine which case applies. Answer the question by selecting one of the following options:
    (A) The submitted answer is a subset of the expert answer and is fully consistent with it.
    (B) The submitted answer is a superset of the expert answer and is fully consistent with it.
    (C) The submitted answer contains all the same details as the expert answer.
    (D) There is a disagreement between the submitted answer and the expert answer.
    (E) The answers differ, but these differences don't matter from the perspective of factuality.
  choice_strings: ABCDE
"""

    messages = [
        {'role': 'system', 'content': system_message},
        {'role': 'user', 'content': user_message}
    ]

    response = get_completion_from_messages(messages)
    return response
```
```python
print(assistant_answer)
```
```python
eval_vs_ideal(test_set_ideal, assistant_answer)
```
```python
assistant_answer_2 = "life is like a box of chocolates"
```
```python
eval_vs_ideal(test_set_ideal, assistant_answer_2)
```


---

