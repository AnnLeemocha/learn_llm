# Language Models, the Chat Format and Tokens èªè¨€æ¨¡å‹ã€èŠå¤©æ ¼å¼å’Œä»¤ç‰Œ
è¦æœ‰æ•ˆä½¿ç”¨å¤§å‹èªè¨€æ¨¡å‹ï¼Œäº†è§£å…¶é‹ä½œæ–¹å¼ã€è¨“ç·´æµç¨‹ä»¥åŠåƒã€Œtokenizerï¼ˆåˆ†è©å™¨ï¼‰ã€é€™é¡ç´°ç¯€æ˜¯éå¸¸é‡è¦çš„ï¼Œé€™äº›éƒ½æœƒç›´æ¥å½±éŸ¿ä½ æ’°å¯«æç¤ºè©ï¼ˆpromptsï¼‰æ™‚ï¼Œæ¨¡å‹çš„å›æ‡‰å“è³ªèˆ‡è¡Œç‚ºã€‚

ä¹Ÿæœƒå­¸ç¿’ LLM çš„èŠå¤©æ ¼å¼ï¼ˆchat formatï¼‰ï¼Œé€™æ˜¯æŒ‡å®šç³»çµ±è¨Šæ¯å’Œä½¿ç”¨è€…è¨Šæ¯çš„ä¸€ç¨®æ–¹å¼ï¼Œå¹«åŠ©ä½ æ›´éˆæ´»åœ°æ§åˆ¶æ¨¡å‹çš„è¡Œç‚ºã€‚

---

## èªè¨€æ¨¡å‹
èªè¨€æ¨¡å‹ï¼ˆLanguage Model, LMï¼‰å¯ä»¥é€éç›£ç£å­¸ç¿’ï¼ˆSupervised Learningï¼‰çš„æ–¹å¼è¨“ç·´ï¼Œå…¶ç›®æ¨™æ˜¯é æ¸¬ä¸‹ä¸€å€‹å–®å­—ï¼Œå³å®Œæˆå¾è¼¸å…¥ ğ‘¥ åˆ°è¼¸å‡º ğ‘¦ çš„å°æ‡‰ã€‚
(æ–‡å­—ç”Ÿæˆ)
* èˆ‰ä¾‹èªªæ˜
  ç•¶ä½ è¼¸å…¥æç¤ºèªå¥ï¼šã€Œæˆ‘å–œæ­¡åƒã€ï¼Œå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰æœƒè©¦åœ–è£œå…¨æ¥ä¸‹ä¾†æœ€æœ‰å¯èƒ½å‡ºç¾çš„å…§å®¹ã€‚ä¾‹å¦‚ï¼Œæ¨¡å‹å¯èƒ½æœƒå›ç­”ï¼š
  1. ã€Œè²æœã€
  2. ã€Œé…ã€
  3. ã€Œèµ·å¸ã€
  4. ...

### ç¾åœ¨ä¸»æµçš„å¤§å‹èªè¨€æ¨¡å‹å¤§è‡´å¯åˆ†ç‚ºå…©ç¨®ï¼š(Base LLM & Instruction Tuned LLM)
1. åŸºç¤ LLMï¼ˆBase LLMï¼‰
   æ ¹æ“šæ–‡å­—è¨“ç·´è³‡æ–™ã€Œé æ¸¬ä¸‹ä¸€å€‹å–®å­—ã€
2. æŒ‡ä»¤å¾®èª¿ LLMï¼ˆInstruction Tuned LLMï¼‰
    * æœƒè©¦åœ–ã€Œç…§è‘—æŒ‡ä»¤åšäº‹ã€
    * è¶Šä¾†è¶Šå¸¸è¢«ä½¿ç”¨

### å¾åŸºç¤ LLM åˆ°æŒ‡ä»¤å¾®èª¿ LLM
* ä½¿ç”¨å¤§é‡è³‡æ–™è¨“ç·´åŸºç¤ LLM
    * ç”¨å¤§é‡è³‡æ–™
    * éœ€è¦å¹¾å€‹æœˆ
* é€²ä¸€æ­¥è¨“ç·´æ¨¡å‹
    1. æ ¹æ“šè¼¸å‡ºèˆ‡éµå¾ªè¼¸å…¥æŒ‡ä»¤çš„ç¯„ä¾‹é€²è¡Œå¾®èª¿ (è¼ƒå°çš„è³‡æ–™)
        * é€™äº›è³‡æ–™é›†æ˜¯å«æœ‰ã€ŒæŒ‡ä»¤èˆ‡è‰¯å¥½å›æ‡‰ã€çš„ç¯„ä¾‹
    2. å–å¾—ä¸åŒ LLM è¼¸å‡ºå“è³ªçš„äººå·¥è©•ç´šï¼Œæ¨™æº–åŒ…æ‹¬æ˜¯å¦æœ‰ç”¨ã€èª å¯¦å’Œç„¡å®³
        * ä¾æ“šå›æ‡‰æ˜¯å¦å…·æœ‰å¹«åŠ©ã€èª å¯¦ã€å®‰å…¨ç­‰æ¨™æº–é€²è¡Œè©•åˆ†ã€‚
    3. èª¿æ•´ LLM ä»¥å¢åŠ å…¶ç”¢ç”Ÿæ›´é«˜è©•ç´šè¼¸å‡ºçš„æ©Ÿç‡ï¼ˆä½¿ç”¨ RLHFï¼šå¾äººé¡å›é¥‹ä¸­é€²è¡Œå¼·åŒ–å­¸ç¿’ï¼‰
        * ä¾è©•åˆ†å¾®èª¿ï¼Œæå‡æ¨¡å‹çš„å›æ‡‰å“è³ª
* åŸºç¤æ¨¡å‹è½‰æˆæŒ‡ä»¤å¾®èª¿æ¨¡å‹åªéœ€å¹¾å¤©ï¼Œè³‡æ–™å’Œç®—åŠ›éœ€æ±‚ä¹Ÿè¼ƒä½ã€‚ä½†é€™æ–¹æ³•ç›®å‰ä¸å¤ªé©ç”¨æ–¼åƒ Excel è¡¨æ ¼é€™é¡çµæ§‹åŒ–è³‡æ–™ã€‚

---

## Tokens (ä»¤ç‰Œ)
æ¨¡å‹é æ¸¬çš„ä¸æ˜¯ã€Œä¸‹ä¸€å€‹è©ã€ï¼Œè€Œæ˜¯ã€Œä¸‹ä¸€å€‹ tokenï¼ˆåˆ†è©å–®ä½ï¼‰ã€ã€‚
* LLM è™•ç†æ–‡å­—çš„å–®ä½æ˜¯ tokenï¼Œè€Œä¸æ˜¯å­—æ¯ã€‚
* ç”¨ tokenizer ï¼ˆåˆ†è©å™¨ï¼‰ï¼ŒæŠŠæ–‡å­—æ‹†è§£æˆ tokenã€‚
* Token æ˜¯å°‡ä¸€æ®µæ–‡å­—åˆ‡æˆå¸¸è¦‹çš„å­—è©æˆ–å­—å…ƒçµ„åˆã€‚
    * å¸¸è¦‹è©é€šå¸¸æ˜¯ä¸€å€‹ tokenï¼Œä¸å¸¸è¦‹è©å‰‡æœƒè¢«æ‹†æˆå¤šå€‹ tokenã€‚
    * ä¾‹å¦‚ï¼š
        ![token sample](images/token%20sample.png)
        * `Learning new things is fun!` 
          â†’ æ¯å€‹è©æˆ–æ¨™é»ç¬¦è™Ÿæ˜¯ 1 å€‹ token
        * `Prompting as powerful developer tool.`
          â†’ `Prompting` è¢«æ‹†æˆ `prom`, `pt`, `ing` å…±ä¸‰å€‹ token
        * `Lollipop` 
          â†’ è¢«æ‹†æˆ `l`, `oll`, `ipop`

### é™åˆ¶èˆ‡è¨ˆç®—
* å°æ–¼è‹±èªè¼¸å…¥ï¼Œ1 å€‹ token å¤§ç´„ä»£è¡¨ 4 å€‹å­—ç¬¦ï¼Œæˆ– 3/4 å€‹å–®å­—ã€‚
* è‹±æ–‡è£¡ï¼Œä¸€å€‹ token ç´„ç­‰æ–¼ 4 å­—å…ƒæˆ– 3/4 å€‹è©ã€‚
* ä¸åŒçš„æ¨¡å‹å°è¼¸å…¥(context)+è¼¸å‡º(completion)ä¸­çš„ token æ•¸é‡æœ‰ä¸åŒçš„é™åˆ¶ã€‚
    * ä»¥ GPT-3.5 Turbo ç‚ºä¾‹ï¼Œcontext ä¸Šé™ç´„ 4,000 tokenï¼Œè¶…å‡ºå°‡è§¸ç™¼ API éŒ¯èª¤ã€‚
* åœ¨é–‹ç™¼ä¸­ï¼Œé™¤éæ“”å¿ƒä½¿ç”¨è€…è¼¸å…¥éé•·è€Œè¶…å‡ºé™åˆ¶ï¼Œå¦å‰‡ä¸å¿…ç‰¹åˆ¥è™•ç† token æ•¸é‡ã€‚è‹¥æœ‰æ­¤ç–‘æ…®ï¼Œå†æª¢æŸ¥é•·åº¦ä¸¦æˆªæ–·ã€‚

---

## èŠå¤©æ ¼å¼ï¼ˆChat Formatï¼‰
å¯ä»¥é€éã€Œç³»çµ±è¨Šæ¯ï¼ˆsystemï¼‰ã€ã€ã€Œä½¿ç”¨è€…è¨Šæ¯ï¼ˆuserï¼‰ã€ã€ã€ŒåŠ©æ‰‹è¨Šæ¯ï¼ˆassistantï¼‰ã€ä¾†æ›´éˆæ´»æ§åˆ¶ LLM çš„è¡Œç‚ºã€‚

---

## æç¤ºæ­£åœ¨å¾¹åº•æ”¹è®Šäººå·¥æ™ºæ…§æ‡‰ç”¨ç¨‹å¼çš„é–‹ç™¼

### ç›£ç£å¼å­¸ç¿’
æ•´é«”å¯èƒ½è¦å¹¾å€‹æœˆ
1. æ”¶é›†æ¨™è¨˜æ•¸æ“š
    * å¹¾ç™¾ç­†ï¼Œå¯èƒ½è¦å¹¾é€±
2. ç”¨é€™äº›è³‡æ–™ä¾†è¨“ç·´ AI æ¨¡å‹ + è©•ä¼°
    * æ•¸å¤©åˆ°æ•¸é€±
3. ä¸Šé›²éƒ¨ç½²å’Œå‘¼å«æ¨¡å‹ (æ¸¬è©¦)
    * æ•¸å¤©åˆ°æ•¸é€±

### åŸºæ–¼æç¤ºçš„äººå·¥æ™ºæ…§ (é–‹ç™¼æ–‡å­—ç›¸é—œçš„æ‡‰ç”¨)
å¯èƒ½å¹¾å°æ™‚å…§å°±å¯ä»¥éƒ¨ç½²ä¸¦å¯¦éš›ä½¿ç”¨
1. æŒ‡å®šæç¤º
    * å¹¾åˆ†é˜æˆ–å¹¾å°æ™‚
2. å‘¼å«æ¨¡å‹ (é€é API é–‹å§‹æ¸¬è©¦)
    * å¹¾å°æ™‚å…§

---

## èªªæ˜ç¯„ä¾‹

### è¨­å®š
è¼‰å…¥ API é‡‘é‘°å’Œç›¸é—œçš„ Python å‡½å¼åº«ã€‚
åœ¨æœ¬èª²ç¨‹ä¸­ï¼Œæˆ‘å€‘ç‚ºæ‚¨æä¾›äº†ä¸€äº›è¼‰å…¥ OpenAI API é‡‘é‘°çš„ç¨‹å¼ç¢¼ã€‚
```python
import os
import openai
import tiktoken
from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv()) # read local .env file
â€‹
openai.api_key  = os.environ['OPENAI_API_KEY']
```

### è¼”åŠ©å‡½æ•¸
åœ¨æ•´å€‹èª²ç¨‹ä¸­ï¼Œæˆ‘å€‘å°‡ä½¿ç”¨ OpenAI çš„ gpt-3.5-turbo æ¨¡å‹å’Œ[èŠå¤©å®Œæˆç«¯é»](https://platform.openai.com/docs/guides/chat)ã€‚

æ­¤è¼”åŠ©åŠŸèƒ½å°‡ä½¿ä½¿ç”¨æç¤ºå’ŒæŸ¥çœ‹ç”¢ç”Ÿçš„è¼¸å‡ºè®Šå¾—æ›´åŠ å®¹æ˜“ã€‚

è¨»ï¼š2023 å¹´ 6 æœˆï¼ŒOpenAI æ›´æ–°äº† gpt-3.5-turboã€‚æ‚¨åœ¨ç­†è¨˜æœ¬ä¸­çœ‹åˆ°çš„çµæœå¯èƒ½èˆ‡å½±ç‰‡ä¸­çš„çµæœç•¥æœ‰ä¸åŒã€‚ä¸€äº›æç¤ºä¹Ÿç¶“éäº†è¼•å¾®ä¿®æ”¹ä»¥ç”¢ç”Ÿæ‰€éœ€çš„çµæœã€‚

```python
def get_completion(prompt, model="gpt-3.5-turbo"):
    messages = [{"role": "user", "content": prompt}]
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=0, # this is the degree of randomness of the model's output 
    )
    return response.choices[0].message["content"]
```

è¨»ï¼š æœ¬èª²ç¨‹çš„æœ¬å¯¦é©—ç­†è¨˜æœ¬å’Œæ‰€æœ‰å…¶ä»–å¯¦é©—ç­†è¨˜æœ¬å‡ä½¿ç”¨ OpenAI åº«ç‰ˆæœ¬ 0.27.0ã€‚

ç‚ºäº†ä½¿ç”¨ OpenAI å‡½å¼åº«ç‰ˆæœ¬ 1.0.0ï¼Œä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥ç”¨ä¾†å–ä»£ get_completion å‡½æ•¸çš„ç¨‹å¼ç¢¼ï¼š

```python
client = openai.OpenAI()

def get_completion(prompt, model="gpt-3.5-turbo"):
    messages = [{"role": "user", "content": prompt}]
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=0
    )
    return response.choices[0].message.content
```

### æç¤ºæ¨¡å‹ä¸¦å–å¾—å®Œæˆ
```python
response = get_completion("What is the capital of France?")
```
```python
print(response)
```

### ä»¤ç‰Œ (Tokens)
æ¨¡å‹é æ¸¬çš„æ˜¯ã€Œä¸‹ä¸€å€‹ tokenï¼ˆåˆ†è©å–®ä½ï¼‰ã€ã€‚æ¨¡å‹ç”¨ tokenizer ï¼ˆåˆ†è©å™¨ï¼‰ï¼ŒæŠŠæ–‡å­—æ‹†è§£æˆ tokenã€‚
```python
response = get_completion("Take the letters in lollipop \
and reverse them")
print(response)
```
â€œlollipopâ€åéä¾†æ‡‰è©²æ˜¯â€œpopillolâ€
```python
response = get_completion("""Take the letters in \
l-o-l-l-i-p-o-p and reverse them""")
```
```python
response
```

### èŠå¤©æ ¼å¼
å¯å¤šè¼ªå°è©±çš„è¼”åŠ©å‡½æ•¸
```python
def get_completion_from_messages(messages, 
                                 model="gpt-3.5-turbo", 
                                 temperature=0, 
                                 max_tokens=500):
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=temperature, # this is the degree of randomness of the model's output
        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut 
    )
    return response.choices[0].message["content"]
```
```python
messages =  [  
{'role':'system', 
 'content':"""You are an assistant who\
 responds in the style of Dr Seuss."""},    
{'role':'user', 
 'content':"""write me a very short poem\
 about a happy carrot"""},  
] 
response = get_completion_from_messages(messages, temperature=1)
print(response)
```
é™åˆ¶è¼¸å‡ºåªå›ä¸€å¥è©±ã€‚
```python
# length
messages =  [  
{'role':'system',
 'content':'All your responses must be \
one sentence long.'},    
{'role':'user',
 'content':'write me a story about a happy carrot'},  
] 
response = get_completion_from_messages(messages, temperature =1)
print(response)
```
çµåˆå¤šç¨®è¼¸å‡ºè¦æ±‚ã€‚(é¢¨æ ¼+ä¸€å¥è©±)
```python
# combined
messages =  [  
{'role':'system',
 'content':"""You are an assistant who \
responds in the style of Dr Seuss. \
All your responses must be one sentence long."""},    
{'role':'user',
 'content':"""write me a story about a happy carrot"""},
] 
response = get_completion_from_messages(messages, 
                                        temperature =1)
print(response)
```
è¼”åŠ©å‡½æ•¸: (å–å¾— token çš„æ•¸é‡)
* æç¤ºï¼ˆpromptï¼‰ç”¨äº†å¤šå°‘ token
* å›è¦†ï¼ˆcompletionï¼‰ç”¨äº†å¤šå°‘ token
* ç¸½å…±ç”¨äº†å¤šå°‘ token
```python
def get_completion_and_token_count(messages, 
                                   model="gpt-3.5-turbo", 
                                   temperature=0, 
                                   max_tokens=500):
    
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=temperature, 
        max_tokens=max_tokens,
    )
    
    content = response.choices[0].message["content"]
    
    token_dict = {
'prompt_tokens':response['usage']['prompt_tokens'],
'completion_tokens':response['usage']['completion_tokens'],
'total_tokens':response['usage']['total_tokens'],
    }

    return content, token_dict
```
```python
messages = [
{'role':'system', 
 'content':"""You are an assistant who responds\
 in the style of Dr Seuss."""},    
{'role':'user',
 'content':"""write me a very short poem \ 
 about a happy carrot"""},  
] 
response, token_dict = get_completion_and_token_count(messages)
```
```python
print(response)
```
```python
print(token_dict)
```

---

## æ³¨æ„äº‹é …
é—œæ–¼åœ¨èª²å ‚ä¹‹å¤–ä½¿ç”¨ OpenAI API çš„æ³¨æ„äº‹é …
è¦å®‰è£ OpenAI Python åº«ï¼š
```python
!pip install openai
```
è©²åº«éœ€è¦é…ç½®ä½ çš„å¸³æˆ¶é‡‘é‘°ï¼Œè©²é‡‘é‘°å¯ä»¥åœ¨[ç¶²ç«™](https://platform.openai.com/account/api-keys)ä¸Šå–å¾—ã€‚
æ‚¨å¯ä»¥åœ¨ä½¿ç”¨è©²åº«ä¹‹å‰å°‡å…¶è¨­å®šç‚º OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸ï¼š
```python
 !export OPENAI_API_KEY='sk-...'
```
æˆ–è€…ï¼Œå°‡ openai.api_key è¨­å®šç‚ºå…¶å€¼ï¼š
```python
import openai
openai.api_key = "sk-..."
```

### API é‡‘é‘°ç®¡ç†çš„å°æŠ€å·§
ä¸è¦åœ¨ç¨‹å¼ä¸­ç›´æ¥å¯«æ˜ä½ çš„ OpenAI API é‡‘é‘°ï¼Œé€™å¾ˆå±éšªã€‚

æ›´å®‰å…¨çš„åšæ³•æ˜¯ä½¿ç”¨ .env æª”æ¡ˆå„²å­˜ä½ çš„ API é‡‘é‘°ï¼Œç„¶å¾Œç”¨ dotenv å¥—ä»¶è¼‰å…¥å®ƒï¼š
```python
from dotenv import load_dotenv, find_dotenv
load_dotenv(find_dotenv())
os.getenv("OPENAI_API_KEY")
```

### é—œæ–¼åæ–œç·šçš„èªªæ˜
åœ¨èª²ç¨‹ä¸­ï¼Œæˆ‘å€‘ä½¿ç”¨åæ–œç·š `\` ä¾†ä½¿æ–‡å­—é©åˆè¢å¹•ï¼Œè€Œç„¡éœ€æ’å…¥æ›è¡Œç¬¦ `\n`ã€‚
ç„¡è«–æ˜¯å¦æ’å…¥æ›è¡Œç¬¦ï¼ŒGPT-3 éƒ½ä¸æœƒå—åˆ°å¤ªå¤§å½±éŸ¿ã€‚ä½†æ˜¯ï¼Œåœ¨ä½¿ç”¨ LLM æ™‚ï¼Œæ‚¨å¯èƒ½æœƒè€ƒæ…®æç¤ºä¸­çš„æ›è¡Œç¬¦è™Ÿæ˜¯å¦æœƒå½±éŸ¿æ¨¡å‹çš„æ•ˆèƒ½ã€‚

### åˆ†éš”ç¬¦è™Ÿå°æŠ€å·§
`###` ä½œç‚ºåˆ†éš”ç¬¦ï¼Œæ˜¯ä¸€å€‹ä¸éŒ¯çš„é¸æ“‡ï¼Œå› ç‚ºå®ƒåœ¨ tokenizer ä¸­åªæœƒè¢«è¦–ç‚ºä¸€å€‹ tokenã€‚


---

