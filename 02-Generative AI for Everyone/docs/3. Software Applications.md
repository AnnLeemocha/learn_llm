# Software Applications

## 在軟體應用程式中使用生成式 AI
### 監督式學習
1. 獲取標記的數據
2. 基於數據訓練 AI 模型
3. 部署 (運行) 模型

### 基於提示的開發
1. 說明文本
2. 審閱文本
3. 調用 LLM 的代碼
4. 代碼列印輸出

![Prompt-based development](images/Prompt-based%20development.png)

### 使用生成式 AI 的工作流程
* 監督式學習
    1. 獲取標記的數據 (1個月)
    2. 基於數據訓練 AI 模型 (3個月)
    3. 部署 (運行) 模型 (3個月)
    * 這個過程需要數月時間，並且通常需要專業的機器學習團隊來完成。完成後，還需要將模型部署到雲端服務上進行運行。

* 基於提示的 AI
    1. 指定提示 (數分鐘/小時)
    2. 部署 (運行) 模型 (數小時/天)
    * 使用生成式 AI 的方法更加簡便，開發者只需要通過簡單的提示（prompt）來告訴 AI 需要完成的任務，然後便能調用大型語言模型來完成任務。這樣的開發方法不需要大量的代碼，開發過程可以在幾小時到幾天內完成。


---


## 親自嘗試生成式 AI 代碼
編碼平臺 (Jupyter 筆記本)
https://learn.deeplearning.ai/courses/genai4e/lesson/xa7gc/activity1

#### GENAI4E_Activity1
1. 設定編程環境，使用程式碼傳送提示至 OpenAI 的雲端託管服務。
```python
import openai
import os

openai.api_key = os.getenv("OPENAI_API_KEY")

def llm_response(prompt):
    response = openai.ChatCompletion.create(
        model='gpt-3.5-turbo',
        messages=[{'role':'user','content':prompt}],
        temperature=0
    )
    return response.choices[0].message['content']
```
2. 定義將餐廳評論情感分類的提示。
```python
prompt = '''
    Classify the following review 
    as having either a positive or
    negative sentiment:

    The banana pudding was really tasty!
'''

response = llm_response(prompt)
print(response)
```

#### GENAI4E_Activity2
1. 建立程式設計環境，使用程式碼傳送提示至 OpenAI 的雲端託管服務。
```python
import openai
import os 

openai.api_key = os.getenv("OPENAI_API_KEY")

def llm_response(prompt):
    response = openai.ChatCompletion.create(
        model='gpt-3.5-turbo',
        messages=[{'role':'user','content':prompt}],
        temperature=0
    )
    return response.choices[0].message['content']
```
2. 建立評論清單。
```python
all_reviews = [
    'The mochi is excellent!',
    'Best soup dumplings I have ever eaten.',
    'Not worth the 3 month wait for a reservation.',
    'The colorful tablecloths made me smile!',
    'The pasta was cold.'
]

all_reviews
```
3. 將評論分類為正面或負面。
```python
all_sentiments = []
for review in all_reviews:
    prompt = f'''
        Classify the following review 
        as having either a positive or
        negative sentiment. State your answer
        as a single word, either "positive" or
        "negative":

        {review}
        '''
    response = llm_response(prompt)
    all_sentiments.append(response)

all_sentiments
```
4. 統計正面和負面評論的數量
```python
num_positive = 0
num_negative = 0
for sentiment in all_sentiments:
    if sentiment == 'positive':
        num_positive += 1
    elif sentiment == 'negative':
        num_negative += 1
print(f"There are {num_positive} positive and {num_negative} negative reviews.")
```


---


## 生成式 AI 專案的生命週期
### 生命週期
1. 專案範圍界定
    * 確定應用程序的目標
2. 構建/改進系統
    * 原型通常會在1到2天內完成。儘管一開始的效果可能不理想，但快速建立原型有助於快速進行內部測試，並及時發現系統錯誤或不準確的情況。
    * 最初是一個原型，我們將隨著時間的推移進行改進
3. 內部評估
    * 根據內部測試發現的錯誤，開發團隊會進行多次改進
    * 這是建立生成式AI應用程序的一個高度實驗性和迭代的過程。
    * 出現不正確的回應，就回到第2步改進模型階段
4. 外部部署和監控
    * 當內部評估顯示系統已經達到一定的準確性後，開發團隊會將其部署到外部並開始監控其表現。
    * 讓客戶訂購，監控 LLM 回應
    * 用戶可能會做出一些奇怪且出乎意料的嘗試
    * 若用戶反應或發現不正確的回應
        * 就回到第3步內部評估階段，而後決定是否回第2步改進模型階段
          
          例如，某些類型的餐廳評論無法準確分類，假設您認為這些類型的錯誤是不可接受的，您可能會決定回去利用這些學習成果來改善提示或進一步改善系統。
          
          例如，漢堡的卡路里式多少?
### 提高性能的工具
建立生成式AI應用的過程是一個高度實驗性、重複嘗試的過程。開發團隊會不斷測試、發現錯誤並修正，以不斷提高系統的準確性和實用性。
* 提示 ([反覆運算改進提示](/zBoeVpjyTH61JLx9y6cI-g#反覆運算改進提示))
  ![Iteratively improving your prompt](images/Iteratively%20improving%20your%20prompt.png)
* 檢索增強生成 （Retrieval Augmented Generation, RAG）
    * 讓 LLM 存取外部資料來源
* 微調模型 (Fine-tune)
    * 根據您的任務調整 LLM
* 預訓練模型 
    * 從零開始訓練 LLM


---


## 成本直覺 (Cost intuition)
### LLM的計費方式？
LLM 的計費是根據生成的token數量進行的。每千個token的價格可能不同，舉例來說：
![LLM example prices](images/LLM%20example%20prices.png)

#### 什麼是token?
token是模型處理文本的單位，通常一個token大致上等於一個單詞或單詞的一部分。常見的詞彙（如“example”）可能只算作一個token，而較少見的詞彙（如“translate”）可能會被分為兩個token。

![What is a token?](images/What%20is%20a%20token.png)

每個token大約等於3/4個字，因此，如果你要生成300個單詞的文本，會產生大約400個token。

### 估算成本
典型的成人閱讀速度：250 字/分鐘。
讓某人與LLM忙碌 1 小時需要多少錢？

#### 人工 (每小時 15,000字，成本 ~10-15美元)
> 60分鐘 × 250字 = 15,000字
> 
> 如果人工成本按照美國最低工資（大約每小時10-15美元）來計算。

#### LLM (<1小時 輸入15,000 + 輸出15,000字，成本 0.08美元)
假設你的提示和生成的輸出字數差不多，那麼需要生成30,000個字（包括輸入和輸出）。
假設LLM每千個token的費用是0.2美分。

> prompt + output = 30,000字
> 
> 30,000字 ÷ 3/4 = 40,000個token
> 
> 40,000個token ÷ 1000個token × 0.002美元 = 0.08美元

如果按照美國最低工資（大約每小時10-15美元）來計算，8美分的額外成本對於保持員工的高效工作來說是微不足道的。這對於每小時提供內容的成本來說非常低。

當然，如果你的產品是免費的，並且有數百萬用戶，這個成本可能會變得非常昂貴。但對於許多應用來說，使用LLM的成本比大多數人想像的要低。

使用大型語言模型進行軟體開發的成本相對較低，尤其是在小規模或內部使用的情況下。雖然規模增大可能會提高成本，但總體來說，LLM的使用成本對於許多應用而言並不昂貴。
