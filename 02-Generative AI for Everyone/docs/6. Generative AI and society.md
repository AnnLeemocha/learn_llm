# Generative AI and society

## 對 AI 的擔憂
生成式 AI 引發的幾個重要社會焦慮，包括是否會加劇人類最壞的衝動、AI 是否會取代許多人類工作，以及最令人擔憂的 AI 是否會導致人類滅絕。

1. AI 是否會放大人類最壞的衝動？
    * 這些偏見來自於訓練 LLM 的大量網絡數據，這些數據既反映了人類的美好品質，也暴露了我們的缺點。
    * 它會放大我們最壞的衝動嗎？
        偏見範例: The _________ was a CEO，可能會出現性別歧視的結果
    * 通過微調和更先進的技術，例如強化學習與人類反饋(RLHF)，使AI模型變得更加公正、尊重和符合人類的道德標準，降低 LLM 的偏見。
    * 回顧: [基於人類反饋的強化學習 (Reinforcement learning from human feedback, RLHF)](/YHS-mf4NQMOcBt6YtMc0CA#基於人類反饋的強化學習 (Reinforcement learning from human feedback, RLHF))
        1. 訓練答案品質（獎勵）模型
        2. 讓 LLM 生成大量回應。進一步訓練它以生成更多獲得高分的回應。

2. AI 是否會取代許多工作，並使人類失業？
    * 以放射科學為例
        * 在2016年，深度學習的先驅 Geoff Hinton 預言 AI 將很快取代放射科醫生
            > 「如果你是放射科醫生，你就像一隻已經走到懸崖邊的郊狼，但還沒有往下看，所以它沒有意識到下面沒有地面。
            >
            >   人們現在應該停止訓練放射科醫生。
            >
            >   很明顯，五年內深度學習將會比放射科醫師做得更好。 」
            >
            >   ―― Geoff Hinton, 2016 
        * 至今，AI並沒有取代放射科醫生，原因有兩點：
            1. 解釋X光片比人們當初預期的更為複雜
            2. 從O\*NET中觀察放射科醫生的任務，可以發現放射科醫生不僅僅是解釋影像，還包括操作設備、與病人溝通、處理程序中的緊急情況等多重任務。
        * 推估放射科醫生任務自動化潛力
            AI 應該能夠輔助影像解讀，但完全取代所有工作任務仍然非常困難。這表明，AI 將更多地增強而不是完全取代工作。
            > 「人工智慧不會取代放射科醫生。
            > 
            > 但使用人工智慧的放射科醫生將取代不使用人工智慧的放射科醫生。 」
            > ―― Curtis Langlotz, Professor of Radiology, Stanford University

3. AI 是否會導致人類滅絕？
    * AI 在某些領域的設計錯誤可能導致災難性後果
        * 自駕車事故
        * 股市崩盤
        * 刑事案件中的不公正判決
    * 但 AI 是否會導致人類滅絕還是無法確定的問題。
        * 滅絕論點不具體
        * 大多數爭論都可以歸結為「它有可能發生」。
        * "這是一種新型技術。"
        
        許多AI專家指出，目前並沒有具體的證據表明 AI將導致人類滅絕。AI 的發展仍需要謹慎，並且應該有完善的控制和安全機制。
    * 完美的控制不需要有價值和安全
        * 人類擁有豐富的經驗來控制許多比任何個人都強大得多的事物，例如公司和民族國家。
        * 許多我們無法完全控制的事物仍然是有價值且安全的。
            例如：飛機，早期的飛機曾經是致命的，但隨著經驗的積累和技術的進步，今天的飛行已經變得安全許多。
        * 如果我們看看人類面臨的真正風險
            例如：氣候變遷和流行病
            ――人工智慧將是解決方案的關鍵部分。


---


## AGI（人工通用智慧，Artificial General Intelligence）
### AGI 的標準定義
:::info
「能執行任何人類能執行的智力任務的 AI。」
:::
* 例子：
    * 像人類一樣學習駕駛：
      只需像青少年一樣練習 20 小時就能學會開車（目前的自駕車系統遠未達到這個水平）。
    * 完成博士論文級別的研究：
      不只是幫助起草或構思，而是能自主進行深入的學術研究。
    * 全方位執行知識型工作：
      能夠完成程式設計師、律師、研究人員等職位中所有需要智慧的工作內容。
* 目前的 AI 技術（例如 LLM）雖然強大，能夠協助許多任務，但距離全面完成所有人類智力任務仍有很長的距離。

### 常見的混淆點
:::info
人工通用智慧(AGI) ≠ 通用技術 (general-purpose technology)
:::
人工智能是一種通用技術，但這並不等於它已經具備 AGI 的能力。
* 通用技術
  指的是 AI 在多個應用領域都能發揮作用，例如客服、寫作、翻譯、分析等等。
* AGI
  要求 AI 具備跨場域、跨任務的自主學習與推理能力，就像人類一樣。

### 何時才能實現 AGI？
* 生物智慧與人工智慧的本質不同：
  AI 通常靠大量資料訓練而來（比任何人類閱讀過的文字都多），但還不具備像人類那樣靈活、抽象、情境化的理解與學習能力。
* 人類智力的多樣性與整合性難以複製：
  我們不只是靠知識工作，還涉及情感理解、人際互動、道德判斷等，這些都是目前 AI 尚未掌握的領域。


---


## 負責任的 AI
以道德、可信賴、並具有社會責任的方式來設計、開發和部署人工智慧技術。
就算一個 AI 專案技術成熟、財務可行，但若違背道德原則，也應該果斷停止。
### 負責任的 AI 的 5 大原則 
1. 公平性（Fairness）
    * 避免 AI 系統放大社會偏見或不平等（例如性別、種族、年齡等偏見）。
2. 透明性（Transparency）
    * 讓受影響的利害關係人了解 AI 系統及其決策。
    * AI 如何做出決策應可被理解與說明，提高用戶、開發者與受影響者的信任。
3. 隱私保護（Privacy）
    * 尊重並保護使用者的個資與資料使用權，並確保機密性。
    * 合法規（如 GDPR 等）
4. 安全性（Security）
    * 防止 AI 系統遭受駭客攻擊或惡意濫用。
    * 確保模型本身的穩定與安全
5. 道德使用（Ethical Use）
    * AI 只應用於對社會有益的場景。
    * 避免用於危害人權、擴大仇恨或不公義的行為。
    
### 負責任的 AI 的三個訣竅
是否符合 5 大原則中有些並未有明確的界線，提供幾個方法來完善如何建立負責任的 AI。
1. 建立一個鼓勵討論和辯論道德議題的文化
    * 鼓勵團隊成員提出倫理、偏見、風險等問題
    * 問題提早被發現，就能提早解決
2. 集思廣益，想出事情可能出錯的原因
    * 使用 五大原則當作風險檢核清單（公平、透明、隱私、安全、道德），進行風險預測與假設。
    * 例如，AI 是否會對某些群體不公平？是否侵犯隱私？用戶是否理解它的邏輯？資料有沒有可能被濫用？
3. 與多元化團隊合作並吸收所有利害關係人的觀點
    * 聆聽不同背景與立場的人（如醫療病患、消費者、基層工作者等）
    * 透過用戶訪談或社會溝通調整方向，避免盲點，改善設計品質與道德面向。


---


## 課程總結
* 生成式人工智慧的工作原理
    * 它能做什麼和不能做什麼
    * 常見用例：寫作、閱讀、聊天
* 生成式人工智慧項目
    * 生成式 AI 專案的生命週期
    * 技術選項：提示、RAG、微調
* 對商業和社會的影響
    * 分析工作中的任務以實現自動化或增強潛力
    * 社會關注、負責任的人工智慧


---


## 構建更智慧的世界
* 智慧 = 應用知識與技能來做出好決策的能力
* 人類智慧成本
    * 現在與過去:
        * 培養一位醫師、教師、研究人員，需要數十年時間與龐大資源
        * 只有最富有的人能「雇用大量人類智慧」
    * 未來:
      AI 可以讓智慧變得「低成本」與「可大規模取得」，可低成本地雇用智慧
        * AI 醫療助理 → 減少看醫生的費用與障礙
        * AI 家教 → 為孩子量身打造輔導計劃
        * AI 顧問 → 幫助你在財務、創業、學習上作出更好的選擇
        * 集體智慧升級 → 幫助社會解決巨大的問題
          (氣候變遷、流行病防治、貧窮、教育不均等)
* AI = 新的「電力」
    * 就像電力改變了世界，AI 將重新定義各行各業與日常生活
    * 我們正快速改進 AI 技術，也不斷探索新的應用方式
* AI 展望
  請善用它，且負責任地使用它
    * 活得更健康
    * 學得更有效率
    * 做決策更有智慧
    * 過上更有意義的生活


