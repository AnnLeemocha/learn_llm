{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 安裝套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.9.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\documents\\學習\\llm\\venv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\documents\\學習\\llm\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\documents\\學習\\llm\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\documents\\學習\\llm\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\documents\\學習\\llm\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
      "Using cached tiktoken-0.9.0-cp311-cp311-win_amd64.whl (893 kB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.11.6 tiktoken-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# .\\venv\\Scripts\\activate\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 計算 Token 用量\n",
    "不同語言差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[今天太陽很大]\n",
      "Token: 9\n",
      "[The sun is very bright today]\n",
      "Token: 6\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "token_ids = tokenizer.encode(\"今天太陽很大\")\n",
    "print(\"[今天太陽很大]\")\n",
    "print(\"Token:\",len(token_ids))  # 輸出 9\n",
    "\n",
    "token_ids = tokenizer.encode(\"The sun is very bright today\")\n",
    "print(\"[The sun is very bright today]\")\n",
    "print(\"Token:\",len(token_ids))  # 輸出 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看字詞裁切結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[photography攝影]\n",
      "b'phot'\n",
      "b'ography'\n",
      "b'\\xe6\\x94'\n",
      "b'\\x9d'\n",
      "b'\\xe5\\xbd\\xb1'\n"
     ]
    }
   ],
   "source": [
    "print(\"[photography攝影]\")\n",
    "for token in tokenizer.encode(\"photography攝影\"):\n",
    "    b = tokenizer.decode_bytes([token])\n",
    "    print(b)\n",
    "\n",
    "# Output: b'phot', b'ography', b'\\xe6\\x94', b'\\x9d', b'\\xe5\\xbd\\xb1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 觀察\n",
    "1. \"photography\" 被拆成了 \"phot\" 與 \"ography\" 兩個 Subwords。\n",
    "2. 「攝」這個字則被拆解成 \\xe6\\x94 與 \\x9d 兩組 Byte 的組合。\n",
    "3. 「影」被完整保留為 \\xe5\\xbd\\xb1 的編碼。\n",
    "\n",
    "photography 直覺上可能會認為應該被切成 \"photo\" 與 \"graphy\"，但這就是 BPE Tokenizer 訓練階段自己統計出來的結果，切成 \"phot\" 與 \"ography\" 可能更貼近訓練語料的分佈。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 比較 GPT-3.5 與 GPT-4 Tokenizer 的差異\n",
    "* 詳細的 Tokenizer 名稱可以參考[官方範例](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)。\n",
    "* 若要相當精準的考慮 Chat Format 對 Token 數量的影響，可以參考[官方的 ChatGPT Prompt 格式範例](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo: <Encoding 'cl100k_base'>\n",
      "gpt-4: <Encoding 'cl100k_base'>\n"
     ]
    }
   ],
   "source": [
    "tk1 = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "tk2 = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "print(\"gpt-3.5-turbo:\", tk1)\n",
    "print(\"gpt-4:\", tk2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
